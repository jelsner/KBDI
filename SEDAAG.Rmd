---
title: "SEDAAG"
author: "Zach"
date: "10/2/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

This file will document/organize work flow as it will be presented at the SEDAAG conference


##Abstract
Seasonal Prediction of Natural Fires in the Apalachicola National Forest

Anthropogenic climate change is shifting the risk of wildfires worldwide. The influence of climate change on fire hazards are diverse and complex and varying by region. Understandably, literature on the U.S. wildfire threat holds a western centric viewpoint. In this study we investigate the fire threat in the Southeast United States. In particular, we examine the association between soil dryness and lightning-ignited wildfires in the Apalachicola National Forest (ANF) located in the Florida Big Bend region. We quantify, for the first time, the relationship between pre-fire season dryness and the number of fires during the fire season with a statistical model. We show that lightning-ignited wildfires are frequent, seasonal events. We define the fire season as occurring from May to July when over 80% of natural fires since 1992 have occurred. We show a strong relationship between dryness in the forest duff layer during April and the number of natural wildfires during the subsequent May through July time period. We estimate soil dryness in the duff layer using the Keetch-Byram Drought Index (KBDI) which is a measure of moisture deficit based on temperature and net rainfall easily computed using daily summary of the day values from first-order weather stations. Given the strong relationship between the KBDI and the number of wildfires we suggest that a skillful seasonal prediction model of fire-season severity might be possible.

##Import libraries and data sets
```{r}
library(lubridate)
library(tidyverse)
library(ggplot2)
#library(ggrepel)
library(ggpp)
library(ggpubr)
library(scales)
library(patchwork)
library(tidycensus)
library(dplyr)
library(readr)
library(sf)
library(tmap)
library(rgeos)
library(RColorBrewer)
library(rgdal)
library(USAboundaries)
library(XML)
library(units)
library(equatiomatic)
library(tinytex)
#library(mpm)
#library(magrittr)
library(texPreview)
library(MASS)
```

Daily summary of the day values from Tallahassee (TLH)
March 1,1940 - April 20, 2020
Includes observed 24hr precip, tmax, and tmin
```{r}
TLH.df <- read_csv(file = 'Data/TLH_Daily1940.csv') %>%
  rename(Date = DATE) %>%
  mutate(Year = year(Date), 
         month = month(Date, label = TRUE, abbr = TRUE),
         doy = yday(Date),
         MaxTemp = TMAX,
         MinTemp = TMIN,
         Rainfall24 = PRCP,
         Rainfall24 = replace_na(Rainfall24, 0),
         Rainfall24mm = Rainfall24 * 25.4)

#Fill in the missing temperature data
TLH.df$MaxTemp[TLH.df$Date == "2005-07-08"] <- 96
```

Calculate KBDI referencing functions that have been built. Append to TLH.df
```{r}
source("netRainfall.R")
TLH.df$NetR <- netRainfall(TLH.df$Rainfall24)

source("droughtIndex.R")
Q <- 269
R <- 59.23 #Average annual rainfall for TLH in inches
TLH.df$Ql <- droughtIndex(Q,R,TLH.df$MaxTemp,TLH.df$NetR)$Ql
TLH.df$Qlm <- TLH.df$Ql * .254  # tenth of an inch to mm
TLH.df$DroughtIndex <- droughtIndex(Q,R,TLH.df$MaxTemp,TLH.df$NetR)$DroughtIndex
```

ANF Boundaries data set:
```{r}
if(!"S_USA.NFSLandUnit" %in% list.files()){
  download.file("https://data.fs.usda.gov/geodata/edw/edw_resources/shp/S_USA.NFSLandUnit.zip",
                "S_USA.NFSLandUnit.zip")
unzip("S_USA.NFSLandUnit.zip")
}

NF_Bounds.sf <- st_read(dsn = "s_USA.NFSLandUnit.shp") %>%
  st_transform(crs = 3086)

anfbounds.sf <- NF_Bounds.sf %>%
  filter(NFSLANDU_2 == "Apalachicola National Forest")
```

Import County Boundaries of the forest. This will make the bounds consistent across both the fire data set and the lightning data set.
```{r}
ANFcountyBounds.sf <- st_read(dsn = "ANFCounties.shp") %>%
  st_transform(crs = 3086)
```

Fires data set:
bounded on counties to match the lightning data boundary. Includes Liberty, Wakulla, Franklin, and Leon. ANF is within these county boundaries.Includes all fire types.
```{r}
#if(!"Fires2018" %in% list.files()){
  #download.file("https://www.fs.usda.gov/rds/archive/products/RDS-2013-0009.5/RDS-2013-0009.5_GPKG.zip",
                #"Data/updatedFireData/Fires2018.zip")
  #unzip("Data/updatedFireData/Fires2018.zip",
        #exdir = "Data/updatedFireData")
#}

county_Fires.sf <- st_read(dsn = "Data/updatedFireData/Data/FPA_FOD_20210617.gpkg", layer = "Fires") %>%
  filter(STATE == "FL") %>%
  st_transform(crs = st_crs(ANFcountyBounds.sf)) %>%
  st_intersection(ANFcountyBounds.sf) %>%
  select(FOD_ID, FIRE_NAME, FIRE_YEAR, DISCOVERY_DATE, NWCG_CAUSE_CLASSIFICATION, NWCG_GENERAL_CAUSE, FIRE_SIZE, FIRE_SIZE_CLASS, LATITUDE, LONGITUDE, NAME, FIPS_CODE, Shape)

#Reformat date column to not include time. Rename to match other merged columns
county_Fires.sf$DISCOVERY_DATE <- as.Date(county_Fires.sf$DISCOVERY_DATE)
county_Fires.sf <- county_Fires.sf %>%
  rename(DISCOVERY_ = DISCOVERY_DATE)

#county lightning fires
county_LF.sf <- county_Fires.sf %>%
  filter(NWCG_GENERAL_CAUSE == "Natural")
```

Bounded to the ANF
```{r}
#all fires
anf_Fires.sf <- county_Fires.sf %>%
  st_transform(crs = st_crs(anfbounds.sf)) %>%
  st_intersection(anfbounds.sf)

#filtered to lighting fires
anf_LF.sf <- anf_Fires.sf %>%
  filter(NWCG_GENERAL_CAUSE == "Natural")
```


lightning data set:
```{r}
#gives lighting data for each individual county based on fips code
lightning.df <- list.files(path = "C:/Users/zlaw9/OneDrive/GITHUB/KDBI code/FIPS_LightningData",
                  pattern = "*.csv", full.names = TRUE) %>%
  lapply(read_csv) %>%
  bind_rows

lightning.df <- lightning.df %>%
  mutate(SEQDAY = as.Date(SEQDAY),
         DAY = day(SEQDAY),
         MONTH = month(SEQDAY),
         YEAR = year(SEQDAY)) %>%
#missing data beyond 5/20/2013 for FIPS #12037. Remove last 5 rows from data set. This addresses the parsing failure and removes data that is NA.
  filter(SEQDAY <=  "2013-05-20")

#make FCOUNT_NLDN column numeric
lightning.df$FCOUNT_NLDN <- as.numeric(lightning.df$FCOUNT_NLDN)

#Combine total lightning strikes in ANF counties by date.
lightning.df <- lightning.df %>%
  group_by(SEQDAY) %>%
  summarise(LightningCount = sum(FCOUNT_NLDN))
```

Viewing fires within the Apalachicola National Forest (437 observations)
```{r}
tmap_mode("view")

tm_shape(anfbounds.sf) +
  tm_borders()

tm_shape(anf_LF.sf) +
  tm_dots(col = "orange")
```

##Exploratory Analysis

Cause of Fires in the Apalachicola National Forest
Natural fires account for nearly 40% of fires in the ANF
```{r}
#table(Fires.sf$NWCG_GENERAL_CAUSE)

df <- anf_Fires.sf %>%
  st_drop_geometry() %>%
  group_by(NWCG_GENERAL_CAUSE) %>%
  summarize(nF = n(),
            perF = nF/nrow(anf_Fires.sf))

#png("C:/Users/zlaw9/OneDrive/Thesis/SEDAAG/PresentationFigures/FireCause.png", width = 733, height = 412)

ggplot(df,
       mapping = aes(y = reorder(NWCG_GENERAL_CAUSE, perF),
                     x = perF,
                     fill = perF)) +
  geom_col() +
  scale_fill_distiller(palette = "Oranges",
                       direction = 1,
                       guide = "none") +
  scale_x_continuous(labels = percent) +
  ylab("") + xlab("") +
  labs(title = "Lightning is the predominant spark for wildfires\nin the Apalachicola National Forest",
       subtitle = "Based on data from 1992-2018",
       caption = "Data source: Short, Karen (2021)")
  #theme_minimal()
  #theme(plot.title = element_text(size = 15),
        #axis.text = element_text(size = 12))

#dev.off()
```

Locations of lightning fires in the ANF
```{r}
ggplot() +
  geom_sf(data = anfbounds.sf, fill = "transparent") +
  geom_sf(data = anf_LF.sf,
          mapping = aes(col = FIRE_SIZE_CLASS)) +
  scale_color_brewer(palette = "Oranges",
                     direction = 1,
                     name = "Size Class: Acres Burned",
                     labels = c(
                       "A: 0-0.25",
                       "B: 0.26-9.9",
                       "C: 10.0-99.9",
                       "D: 100-299",
                       "E: 300-999",
                       "F: 1000-4999",
                       "G: 5000+")) +
  theme_bw() +
  labs(title = "Location of natural-caused wildfires in the\nApalachicola National Forest (1992-2018)",
       subtitle = "Darker color points indicates the fire resulted in a larger burn area",
       caption = "Data source: Short, Karen (2021)")
```

Plot the number of lightning fires per month
Over 80% of lightning-sparked wildfires in the ANF occur during May-July
```{r}
df <- anf_LF.sf %>%
  st_drop_geometry() %>%
  mutate(MonthF = factor(month.name[month(DISCOVERY_)], 
                         levels = rev(month.name), 
                         ordered = TRUE)) %>%
  group_by(MonthF, .drop = FALSE) %>%
  summarize(nF = n(),
            perF = nF/nrow(anf_LF.sf))

ggplot(data = df,
       mapping = aes(y = MonthF, 
                     x = perF,
                     fill = perF)) +
  geom_col() +
  scale_fill_distiller(palette = "Oranges",
                       direction = 1,
                       guide = "none") +
  scale_x_continuous(labels = percent) +
  xlab("") + ylab("") +
  labs(title = "Over 80% of lightning-sparked wildfires in the\nApalachicola National Forest occur during May-July",
       subtitle = "Percentage of all lightning-sparked wildfires by month",
       caption = "Period of record: 1992-2018, Data source: Short, Karen (2021)") +
  theme_minimal() +
  theme(plot.title = element_text(size = 15),
        axis.text = element_text(size = 10)) 
  #theme_dark()
```

Plot average monthly rainfall and max temperatures
```{r}
df <- TLH.df %>%
  filter(Year >= 1941 & Year <= 2019) %>%
  group_by(month) %>%
  summarize(totalRain = sum(Rainfall24mm),
            avgMonthlyTotalRain = totalRain/(2019 - 1941 + 1),
            avgDailyHighTemp = mean(MaxTemp))

p1 <- ggplot(data = df,
             mapping = aes(x = month, y = avgMonthlyTotalRain, fill = avgMonthlyTotalRain)) +
        geom_col() +
        scale_fill_distiller(palette = "Greens",
                         direction = 1, 
                         guide = 'none') +
        theme_dark() +
        labs(x = "", y = "(mm)",
             title = "Average monthly rainfall amount in the Apalachicola National Forest",
             subtitle = "1941-2019") +
        theme(plot.title = element_text(size = 15),
              plot.subtitle = element_text(size = 13),
              axis.text = element_text(size = 11))


p2 <- ggplot(data = df,
             mapping = aes(x = month, y = avgDailyHighTemp, color = avgDailyHighTemp)) +
        geom_point(size = 4) +
        scale_color_distiller(palette = "Oranges",
                              direction = 1, 
                              guide = 'none') +
        scale_y_continuous(limits = c(60, 100)) +
        theme_dark() +
        labs(x = "", y = "(Â°F)",
             title = "Average daily high temperature in the Apalachicola National Forest",
             subtitle = "1941-2019") +
        theme(plot.title = element_text(size = 15),
              plot.subtitle = element_text(size = 13),
              axis.text = element_text(size = 10))

(p1 / p2) +
  labs(caption = "Period of record: 1941-2019, Data source: NWSFO Tallahassee")
```

Average number of lightning strikes in the ANF
```{r}
lightningAvg.df <- lightning.df %>%
  filter(year(SEQDAY) <= 2012) %>%
  mutate(MonthF = factor(month.name[month(SEQDAY)],
                         levels = rev(month.name),
                         ordered = TRUE)) %>%
  group_by(MonthF, .drop = FALSE) %>%
  summarize(avgLightningCount = sum(LightningCount)/(2012-1986))
```

Plot average lightning
```{r}
lightningAvg.df %>%
  ggplot(mapping = aes(y = MonthF,
                       x = avgLightningCount,
                       fill = avgLightningCount)) +
  geom_col() +
  #scale_fill_gradientn(colors = brewer.pal(4, "OrRd"),
  scale_fill_gradientn(colors = brewer.pal(4, "Blues"),                     
                       guide = "none") +
  labs(x = "", y = "",
       title = "Lightning in the Apalachicola National Forest peaks from June-August",
       subtitle = "Daily average number of cloud-to-ground lightning strikes by month",
       caption = "Period of record 1986 - 2012, Data Source: NCEI") +
  #theme_dark()
  theme_minimal()
```

Monthly average soil moisture deficit.
```{r}
TLH.df %>%
  filter(Year >= 1941 & Year <= 2019) %>%
  mutate(MonthF = factor(month.name[month(Date)], 
                         levels = rev(month.name), 
                         ordered = TRUE)) %>%
  group_by(MonthF, .drop = FALSE) %>%
  summarize(AvgSoilMoistureDeficit = mean(Qlm)) %>%
ggplot(mapping = aes(y = MonthF, 
                     x = AvgSoilMoistureDeficit,
                     fill = AvgSoilMoistureDeficit)) +
  geom_col() +
  scale_fill_gradientn(colors = terrain.colors(5),
                       guide = 'none') +
  labs(x = "", y = "",
       title = "May through November is the dry season in the Apalachicola National Forest",
       subtitle = "Average dryness (mm)",
       caption = "Period of record: 1941-2019, Data source: NWSFO Tallahassee") +
  theme_dark() 
```

Another interpretation of soil moisture plot
```{r}
TLH.df %>%
  filter(Year >= 1941 & Year <= 2019) %>%
  group_by(month, Year) %>%
  summarise(Avg = mean(Qlm)) %>%
  ggplot(aes(x = Year, y = Avg, color = Avg)) +
  geom_smooth(method = lm, se = FALSE, color = "gray70") +
  geom_point() +  
  scale_color_gradientn(colors = terrain.colors(5), guide = "none") +
  scale_y_continuous(limits = c(0, 201)) +
  scale_x_continuous(limits = c(1940, 2020), breaks = c(1950, 1980, 2010)) +
  ylab("") + xlab("") +
  facet_wrap(~ month, ncol = 12) +
  theme_dark() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Risk of wildfires is increasing in the Apalachicola National Forest.",
       subtitle = "Monthly average dryness (mm) by year with trend line (gray)", 
       caption = "Period of record: 1941-2019, Data source: NWSFO Tallahassee") 
```

##General linear regression - Study how KBDI impacts lightning wildfire occurrence.

Filter the KBDI data set to match the time frame of the fire data set (1992 - 2018)
```{r}
TLH_fireYrs.df <- TLH.df %>%
  filter(Year >= 1992 & Year <= 2018)
```

create a data frame for the number of fires that occurred on a given day
```{r}
countfires.df <- anf_LF.sf %>%
  count(DISCOVERY_) %>%
  rename(FireCount = n, Date = DISCOVERY_)
```

Merge the KBDI and fire count data sets
```{r}
KBDI_fire.df <- left_join(x = TLH_fireYrs.df, y = countfires.df, by = c("Date" = "Date")) %>%
  select(Date, FireCount, Ql, Qlm, DroughtIndex)

KBDI_fire.df$fireBool <- !is.na(KBDI_fire.df$FireCount)
```

Create a cm column for daily soil moisture deficit
```{r}
KBDI_fire.df <- KBDI_fire.df %>%
  mutate(Qlcm = Qlm / 10)
```


Regression Model
```{r}
glmQl <- glm(formula = fireBool~Ql, family = binomial, data = KBDI_fire.df)

pred_glmQl <- predict(object = glmQl,
                      type = "response",
                      se.fit = TRUE)

low_bound <- pred_glmQl$fit - (1.96*pred_glmQl$se.fit)
up_bound <- pred_glmQl$fit + (1.96*pred_glmQl$se.fit)

ggplot(mapping = aes(x = KBDI_fire.df$Ql, y = pred_glmQl$fit)) +
  geom_ribbon(aes(ymin = low_bound, ymax = up_bound), fill = "grey") +
  geom_line(color = "blue") +
  #stat_regline_equation() +
  #stat_cor(aes(label = ..rr.label..), label.x = 0, label.y = .155) +
  ylab("Predicited Probablility") +
  xlab("Daily KBDI") +
  labs(
    title = "Predicted Probability of Lightning Fire Occurrence Based on Daily KBDI Values",
    subtitle = "Line of Fitted Values With a 95% Confidence Interval",
    caption = "Period of Record: 1992 to 2018")
```

```{r}
#extract_eq(glmQl, use_coefs = TRUE, coef_digits = 4, fix_signs = FALSE)
```


$$
\log\left[ \frac { \widehat{P( \operatorname{fireBool} = \operatorname{TRUE} )} }{ 1 - \widehat{P( \operatorname{fireBool} = \operatorname{TRUE} )} } \right] = -5.5013 + 0.0049(\operatorname{Ql})
$$

Create a data frame to show a further distribution of the data
```{r}
KBDI_fire.df %>%
  group_by(DroughtIndex) %>%
  count(DroughtIndex)

ggplot(KBDI_fire.df, aes(x = DroughtIndex)) + geom_histogram()
```


Another way of plotting
```{r}
KBDI_fire.df$glmQl_Pred <- glmQl$fitted.values
```

This code chunk takes a long time to knit
```{r}
#ggplot(KBDI_fire.df, aes(x = Ql, y = glmQl_Pred)) +
  #geom_line(color = "blue") +
#  geom_smooth(method = "glm", formula = y ~ x,
#              method.args = list(family = poisson(link = "log")))+
#  ylab("Predicited Probablility") +
#  xlab("Daily KBDI") +
#  labs(
#    title = "Predicted Probability of Lightning Fire Occurrence Based on Daily KBDI Values",
#    subtitle = "With 95% Confidence Interval",
#    caption = "Period of Record: 1992 to 2018")
```


This is a plot of the generalized linear regression fitted values
```{r}
ggplot(KBDI_fire.df, aes(x = Ql, y = glmQl_Pred)) +
  #geom_line(color = "blue") +
  geom_smooth(method = "glm")+
  ylab("Predicited Probablility") +
  xlab("Daily KBDI") +
  labs(
    title = "Predicted Probability of Lightning Fire Occurrence Based on Daily KBDI Values",
    subtitle = "With 95% Confidence Interval",
    caption = "Period of Record: 1992 to 2018")
```

Ql is statistically significant
```{r}
summary(glmQl)
```

Filtered to fire season months
```{r}
KBDI_fireFS.df <- KBDI_fire.df %>%
  filter(month(Date) == 05 | month(Date) == 06 | month(Date) == 07)

glmQlFS <- glm(formula = fireBool ~ Ql, family = binomial, data = KBDI_fireFS.df)

pred_glmQlFS <- predict(object = glmQlFS,
                      type = "response",
                      se.fit = TRUE)

low_bound <- pred_glmQlFS$fit - (1.96*pred_glmQlFS$se.fit)
up_bound <- pred_glmQlFS$fit + (1.96*pred_glmQlFS$se.fit)

ggplot(mapping = aes(x = KBDI_fireFS.df$Ql, y = pred_glmQlFS$fit)) +
  geom_ribbon(aes(ymin = low_bound, ymax = up_bound), fill = "grey") +
  geom_line(color = "blue") +
  ylab("Predicited Probablility") +
  xlab("Daily Ql") +
  labs(
    title = "Predicted Probability of Fire Occurrence Based on Daily KBDI Values\nFiltered By Fire Season Months",
    subtitle = "With 95% Confidence Interval",
    caption = "Fire Season Months (May - July) 1992 - 2018")
```

Ql is statistically significant
```{r}
summary(glmQlFS)
```





Adjust Binomial Regression model to represent KBDI in cm (SI units)
```{r}
glmQlcm <- glm(formula = fireBool~Qlcm, family = binomial, data = KBDI_fire.df)

pred_glmQlcm <- predict(object = glmQlcm,
                      type = "response",
                      se.fit = TRUE)

low_bound <- pred_glmQlcm$fit - (1.96*pred_glmQlcm$se.fit)
up_bound <- pred_glmQlcm$fit + (1.96*pred_glmQlcm$se.fit)

ggplot(mapping = aes(x = KBDI_fire.df$Qlcm, y = pred_glmQlcm$fit)) +
  geom_ribbon(aes(ymin = low_bound, ymax = up_bound), fill = "grey") +
  geom_line(color = "blue") +
  ylab("Predicited Probablility") +
  xlab("Soil Moisture Deficit (cm)") +
  #labs(
    #title = "Predicted Probability of Lightning Fire Occurrence\nBased on Daily Soil Moisture Deficit Values",
    #subtitle = "Line of Fitted Values With a 95% Confidence Interval",
    #caption = "Period of Record: 1992 to 2018")
  theme_minimal()
```

```{r}
extract_eq(glmQlcm, use_coefs = TRUE, coef_digits = 4, fix_signs = FALSE)
```

$$
\log\left[ \frac { \widehat{P( \operatorname{fireBool} = \operatorname{TRUE} )} }{ 1 - \widehat{P( \operatorname{fireBool} = \operatorname{TRUE} )} } \right] = -5.5013 + 0.1937(\operatorname{Qlcm})
$$


##General linear regression - Study how the number of lightning strikes on a given day impacts lightning wildfire occurrence

In modeling with lightning, we need to use the county_LF.sf data set because the lighting data set is bounded to the county boarders
```{r}
count_cFires.df <- county_LF.sf %>%
  count(DISCOVERY_) %>%
  rename(FireCount = n, Date = DISCOVERY_)
```

Each data set must have the same time bounds
```{r}
count_cFiresYrs.df <- count_cFires.df %>%
  filter(year(Date) <= 2012)

lightningYrs.df <- lightning.df %>%
  filter(year(SEQDAY) >= 1992 & year(SEQDAY) <= 2012)
```

merge lightning count data and counted fire data
```{r}
light_fires.df <- left_join(x = lightningYrs.df, y = count_cFiresYrs.df, by = c("SEQDAY" = "Date")) %>%
  rename(Date = SEQDAY) %>%
  select(Date, LightningCount, FireCount)

light_fires.df$FireBool <- !is.na(light_fires.df$FireCount)
```

general linear regression
```{r}
glmLightning <- glm(formula = FireBool ~ LightningCount, family = binomial, data = light_fires.df)

#probabilities based on glm
pred_glmLightning <- predict(object = glmLightning,
                             type = "response",
                             se.fit = TRUE)

#creating confidence interval
low_bound <- pred_glmLightning$fit - (1.96*pred_glmLightning$se.fit)
up_bound <- pred_glmLightning$fit + (1.96*pred_glmLightning$se.fit)

ggplot(mapping = aes(x = light_fires.df$LightningCount, y = pred_glmLightning$fit)) +
  geom_ribbon(aes(ymin = low_bound, ymax = up_bound), fill = "grey") +
  geom_line(color = "blue") +
  ylab("Predicited Probablility") +
  xlab("Number of Lightning Strikes") +
  #labs(
    #title = "Predicted Probability of a Fire Occurrence Based on the\nNumber of Lightning Strikes in a Day",
    #subtitle = "With a 95% Confidence Interval",
    #caption = "Period of Record: 1992 to 2012")
  theme_minimal()
```

lightning count is statistically significant to occurrence of wildfires.
```{r}
summary(glmLightning)
```

Include fitted values in the table
```{r}
light_fires.df$fit <- glmLightning$fitted.values
```

Exploring the confidence intervals
```{r}
temp.df <- data.frame(LightningCount = 2794)
predict.glm(glmLightning, newdata = temp.df, type = "response", se.fit = TRUE)
```


```{r}
extract_eq(glmLightning, use_coefs = TRUE, coef_digits = 4, fix_signs = FALSE)
```

$$
\log\left[ \frac { \widehat{P( \operatorname{FireBool} = \operatorname{TRUE} )} }{ 1 - \widehat{P( \operatorname{FireBool} = \operatorname{TRUE} )} } \right] = -3.2102 + 0.0012(\operatorname{LightningCount})
$$

Filtered to fire season months
```{r}
light_firesFS.df <- light_fires.df %>%
  filter(month(Date) == 05 | month(Date) == 06 | month(Date) == 07)

glmLightningFS <- glm(formula = FireBool ~ LightningCount, family = binomial, data = light_firesFS.df)

#probabilities based on glm
pred_glmLightning <- predict(object = glmLightningFS,
                             type = "response",
                             se.fit = TRUE)

#creating confidence interval
low_bound <- pred_glmLightning$fit - (1.96*pred_glmLightning$se.fit)
up_bound <- pred_glmLightning$fit + (1.96*pred_glmLightning$se.fit)

ggplot(mapping = aes(x = light_firesFS.df$LightningCount, y = pred_glmLightning$fit)) +
  geom_ribbon(aes(ymin = low_bound, ymax = up_bound), fill = "grey") +
  geom_line(color = "blue") +
  ylab("Predicited Probablility") +
  xlab("Number of Lightning Strikes") +
  labs(
    title = "Predicted Probability of a Fire Occurrence Based on the Number of Lightning Strikes in a Day During the Fire Season",
    subtitle = "With a 95% Confidence Interval",
    caption = "Period of Record: 1992 to 2012 Fire Seasons (May - July)")
```

##Study how the burned area over the past year may impact fire occurance.

Create a data frame to include the area that was burned over the past year.
```{r}
anf_Fires.sf <- anf_Fires.sf %>%
  mutate(InSeason = DISCOVERY_ >= as.Date(paste0(as.character(FIRE_YEAR), "-04", "-30")) & DISCOVERY_ <= as.Date(paste0(as.character(FIRE_YEAR+1), "-04", "-29"))) %>%
   mutate(burnedGroupStart = as.Date(paste0(as.character(FIRE_YEAR), "-04", "-30"))) %>%
   mutate(burnedGroupEnd = as.Date(paste0(as.character(FIRE_YEAR+1), "-04", "-29")))

#anf_Fires.sf <- anf_Fires.sf %>%
#  mutate(burnedGroupStart = as.Date(paste0(as.character(FIRE_YEAR), "-04", "-30"))) %>%
#  mutate(burnedGroupEnd = as.Date(paste0(as.character(FIRE_YEAR+1), "-04", "-29")))

for(i in 1:length(anf_Fires.sf$InSeason)){
  if (anf_Fires.sf$InSeason[i] == FALSE){
    anf_Fires.sf$burnedGroupStart[i] <- as.Date(paste0(as.character(anf_Fires.sf$FIRE_YEAR[i]-1), "-04", "-30"))
    anf_Fires.sf$burnedGroupEnd[i] <- as.Date(paste0(as.character(anf_Fires.sf$FIRE_YEAR[i]), "-04", "-29"))
  }
}

anf_Fires.sf <- anf_Fires.sf %>%
  unite(col = "burnedGroupInterval", c("burnedGroupStart", "burnedGroupEnd"), sep = " -- ") %>%
  #rearrange order of columns
  select(FOD_ID:DISCOVERY_, burnedGroupInterval, NWCG_CAUSE_CLASSIFICATION:Shape)
```

Group data by burned periods and sum the total acres burned over that period
Note this does not include fires in the first 3 months of the data set
```{r}
burnedArea.sf <- anf_Fires.sf %>%
  group_by(burnedGroupInterval) %>%
  summarise(acresBurned = sum(FIRE_SIZE)) %>%
  #create column to define the year the data will be used to forecast for
  mutate(forecastYear = substr(burnedGroupInterval, 15, 18)) %>%
  #reorder columns
  select(forecastYear, burnedGroupInterval:acresBurned) %>%
  #convert forecastYear to an int/ double so it will merge
  transform(forecastYear = as.numeric(forecastYear)) %>%
  filter(forecastYear <= 2018)
```

Create a count of natural wildfires occurring in the anf during the fire season. This will be merged with the burned acres data frame.
```{r}
seasonFires.sf <-  anf_LF.sf %>%
  filter(month(DISCOVERY_) == 05 | month(DISCOVERY_) == 06 | month(DISCOVERY_) == 07) %>%
  count(FIRE_YEAR) %>%
  rename(Year = FIRE_YEAR, nFIRES = n) %>%
  st_set_geometry(NULL)
```

Merge burned data frame with the number of lightning wildfires that occurred in the Apalachicola National Forest for each year.
```{r}
burnedArea.sf <- left_join(x = burnedArea.sf, y = seasonFires.sf, by = c("forecastYear" = "Year"))

burnedArea.sf$nFIRES <- replace_na(burnedArea.sf$nFIRES, 0)
```

The model finds that the number of acres burned over the past year is not statistically significant
There is minimal evidence of a relationship between the number of acres burned and the number of natural fires that occur during the fire season.
p-value = 0.0604
correlation coefficient = 0.0966; we would expect a negative slope and a negative correlation.
correlation coefficient model residuals = -0.0029
```{r}
burnedGLM <- glm(formula = nFIRES ~ acresBurned, family = poisson, data = burnedArea.sf)

pred_burnedGLM <- predict(object = burnedGLM,
                         type = "response",
                         se.fit = TRUE)

summary(burnedGLM)

cor(burnedArea.sf$acresBurned, burnedArea.sf$nFIRES)

#correlation of model residuals
cor(burnedArea.sf$acresBurned, resid(burnedGLM))
```

Explore area as a percentage of the forest that was burned.
```{r}
st_area(anfbounds.sf) #2564052729 m^2
drop_units(st_area(anfbounds.sf))/1000000 #2564.053 kilometers^2
drop_units(st_area(anfbounds.sf))/4047 #approximately 633,568.7 acres
```

Create a column within the burnedArea.sf data frame to represent the percentage of the forest burned prior to the fire season
```{r}
burnedArea.sf <- burnedArea.sf %>%
  mutate(percentBurned = (acresBurned/(drop_units(st_area(anfbounds.sf))/4047))*100) %>%
  #reorder columns
  select(forecastYear:acresBurned, percentBurned, nFIRES:Shape)
```

create model based on the percent of forest that was burned.
We find the percent of forest burned is not statistically significant (p-value = 0.146)
The correlation coefficient suggests no relationship (0.0773)
The correlation coefficient of the residuals = -0.00292 (Same as the area burned model)
```{r}
percentBurnedGLM <- glm(formula = nFIRES ~ percentBurned, family = poisson, data = burnedArea.sf)

pred_percentBurnedGLM <- predict(object = percentBurnedGLM,
                         type = "response",
                         se.fit = TRUE)

summary(percentBurnedGLM)

cor(burnedArea.sf$percentBurned, burnedArea.sf$nFIRES)

#correlation of model residuals
cor(burnedArea.sf$percentBurned, resid(percentBurnedGLM))
```

Create a poisson plot
Percentage Burned
```{r}
#creating confidence interval
low_bound <- pred_percentBurnedGLM$fit - (1.96*pred_percentBurnedGLM$se.fit)
up_bound <- pred_percentBurnedGLM$fit + (1.96*pred_percentBurnedGLM$se.fit)

ggplot(mapping = aes(x = burnedArea.sf$percentBurned, y = pred_percentBurnedGLM$fit)) +
  geom_ribbon(aes(ymin = low_bound, ymax = up_bound), fill = "grey") +
  geom_line(color = "blue") +
  ylab("Predicted Number of Fires") +
  xlab("Percentage of Forest Burned") +
  labs(
    title = "Predicted Number of Fires Based on the Forest Area Burned in the Last Year",
    subtitle = "With a 95% Confidence Interval",
    caption = "Period of Record: April 1992 to July 2018")
```

Area Burned
```{r}
#creating confidence interval
low_bound <- pred_burnedGLM$fit - (1.96*pred_burnedGLM$se.fit)
up_bound <- pred_burnedGLM$fit + (1.96*pred_burnedGLM$se.fit)

ggplot(mapping = aes(x = burnedArea.sf$acresBurned, y = pred_burnedGLM$fit)) +
  geom_ribbon(aes(ymin = low_bound, ymax = up_bound), fill = "grey") +
  geom_line(color = "blue") +
  geom_point(aes(x = burnedArea.sf$acresBurned, y = burnedArea.sf$nFIRES)) +
  stat_regline_equation() +
  stat_cor(aes(label = ..rr.label..), label.x = 0, label.y = 40) +
  ylab("Predicted Number of Fires") +
  xlab("Acres of Forest Burned") +
  labs(
    title = "Predicted Number of Fires Based on the Forest Area Burned in the Last Year",
    subtitle = "With a 95% Confidence Interval",
    caption = "Period of Record: April 1992 to July 2018")
```

##Model/Plot Adjustments based on meeting 11/9/2021

Create a bar chart showing the number of fires per year over the data period
```{r}
seasonFires.sf %>%
  ggplot(mapping = aes(x = Year, 
                       y = nFIRES, 
                       fill = nFIRES)) +
  geom_col() +
  scale_fill_gradientn(colors = brewer.pal(4, "OrRd"),
                       guide = "none") +
  scale_x_continuous(breaks = seq(1995, 2015, 5)) +
  ylab("Number of Fires") +
  xlab("Year") +
  labs(
    title = "Total Number of Fires During the Fire Season",
    caption = "Period of Record: 1992 to 2018") +
  theme_dark()
```


Add April 30th KBDI to the seasonFires.sf data frame
```{r}
April30.df <- KBDI_fire.df %>%
  filter(month(Date) == 04 & day(Date) == 30) %>%
  select("Date", "Ql", "Qlm", "Qlcm") %>%
  rename(KBDI_April30 = Ql) %>%
  mutate(Year = year(Date))

#make April30.df left table so that years 1997 and 2005 are filled as zeros
seasonFires.sf <- left_join(x = April30.df, y = seasonFires.sf, by = c("Year" = "Year")) %>%
  select("Year", "nFIRES", "KBDI_April30")
seasonFires.sf$nFIRES <- replace_na(seasonFires.sf$nFIRES, 0)
```

Create a linear null model and general linear regression
```{r}
formula0 <- lm(nFIRES ~ 1, data = seasonFires.sf)
glm0 <- glm(formula0, data = seasonFires.sf, family = poisson)
summary(glm0)
```

create linear model of nFIRES and KBDI
```{r}
formula1 <- lm(nFIRES ~ KBDI_April30, data = seasonFires.sf)
#glm1 <- glm(formula1, data = seasonFires.sf, family = poisson)
```


Poisson Regression
```{r}
glm1 <- glm(nFIRES ~ KBDI_April30, data = seasonFires.sf, family = poisson)
```


compare models. How is this interpreted? Google
```{r}
anova(glm0, glm1)
```

visualize the data with actual fire points
```{r}
ggplot(glm1, aes(x= KBDI_April30, y = nFIRES)) +
  geom_point()+
  geom_smooth(method = "glm") +
  ylab("Number of Fires") +
  xlab("KDBI on April 30th") +
  labs(
    title = "Predicted Number of Fires During the Fire Season Based on April 30th KBDI",
    subtitle = "With a 95% Confidence Interval",
    caption = "Period of Record: 1992 to 2018")
```

Explore the Predicted Values
```{r}
seasonFires.sf$glm1_fit <- glm1$fitted.values
```

view fire plot with predicted values based on april KBDI (fitted values of the model)
```{r}
ggplot(seasonFires.sf, aes(x = KBDI_April30, y = glm1_fit)) +
  geom_point() +
  geom_smooth(method = "glm")+
  stat_regline_equation() +
  ylab("Predicted Number of Fires") +
  xlab("KDBI on April 30th") +
  labs(
    title = "Predicted Number of Fires During the Fire Season Based on April 30th KBDI",
    subtitle = "With a 95% Confidence Interval",
    caption = "Period of Record: 1992 to 2018")
```

visualize the poisson model
```{r}
ggplot(seasonFires.sf, aes(x = KBDI_April30, y = nFIRES)) +
  geom_point() +
  geom_smooth(method = "glm", formula = y ~ x,
              method.args = list(family = poisson(link = "log"))) +
  #stat_regline_equation(formula = y ~ x) +
  ylab("Number of Fires") +
  xlab("KDBI on April 30th") +
  labs(
    title = "Predicted Number of Fires During the Fire Season Based on April 30th KBDI",
    subtitle = "With a 95% Confidence Interval",
    caption = "Period of Record: 1992 to 2018")
```

Equation of glm1 regression line
```{r}
extract_eq(glm1, use_coefs = TRUE, coef_digits = 4, fix_signs = FALSE)
```

$$
\log ({ \widehat{E( \operatorname{nFIRES} )} })  = 0.7296 + 0.0046(\operatorname{KBDI\_April30})
$$

Exploring the confidence intervals
```{r}
temp.df <- data.frame(KBDI_April30 = 0)
predict.glm(glm1, newdata = temp.df, type = "response", se.fit = TRUE)
```

create histogram to show the distribution of the data
April 30 KBDI
```{r}
ggplot(seasonFires.sf, aes(x = KBDI_April30)) + 
  geom_histogram(aes(y = ..density..), binwidth = 50, color = "darkblue", fill = "lightblue") +
  scale_x_continuous(breaks = seq(0,700, 100)) +
  geom_density(alpha = .2, fill = 'blue') +
  geom_vline(aes(xintercept = mean(KBDI_April30)),
             color = "red", linetype = "solid", size = 1) +
  geom_vline(aes(xintercept = median(KBDI_April30)),
             color = "black", linetype = "dashed", size = 1)
  
```

Fires
```{r}
ggplot(seasonFires.sf, aes(x = nFIRES)) + 
  geom_histogram(aes(y = ..density..), binwidth = 5, color = "darkblue", fill = "lightblue") +
  scale_x_continuous(breaks = seq(0, 50, 5)) +
  geom_density(alpha = .2, fill = 'blue') +
  geom_vline(aes(xintercept = mean(nFIRES)),
             color = "red", linetype = "solid", size = 1) +
  geom_vline(aes(xintercept = median(nFIRES)),
             color = "black", linetype = "dashed", size = 1)
```



```{r}
# Install from CRAN
##install.packages('rmarkdown')

# Or if you want to test the development version,
# install from GitHub
#if (!requireNamespace("devtools"))
#  install.packages('devtools')
#devtools::install_github('rstudio/rmarkdown')
```



```{r}
#tinytex::install_tinytex()

#tinytex::parse_install()

#installr::install.MikTeX

#update.packages(ask = FALSE, checkBuilt = TRUE)
#tinytex::tlmgr_update()

#tinytex::pdflatex('test.tex')

#tinytex::latexmk()

#tex_preview(extract_eq(glm1, use_coefs = TRUE, fix_signs = FALSE))
```


Model 2 will predict the number of fires by adding the prior area burned to the model.

add the area burned over the prior season to seasonFires.sf
```{r}
seasonFires.sf <- left_join(x = seasonFires.sf, y = burnedArea.sf, by = c("Year" = "forecastYear")) %>%
  select("Year":"percentBurned") %>%
  rename(nFIRES = nFIRES.x)
```

Acres burned is not statistically significant (p-value = 0.092)
```{r}
temp <- seasonFires.sf %>%
  filter(Year >= 1993)
formula2 <- lm(nFIRES ~ KBDI_April30 + acresBurned, data = temp)
#glm2 <- glm(formula2, data = temp, family = poisson)

#summary(glm2)
```


Poisson Regression
```{r}
temp <- seasonFires.sf %>%
  filter(Year >= 1993)
glm2 <- glm(nFIRES ~ KBDI_April30 + acresBurned, data = temp, family = poisson)
```

Include fitted values in temp table
```{r}
temp$glm2_fit <- glm2$fitted.values
```

change in fitted values
```{r}
temp$change <- temp$glm1_fit - temp$glm2_fit
```


```{r}
extract_eq(glm2, use_coefs = TRUE, coef_digits = 6, fix_signs = FALSE)
```

$$
\log ({ \widehat{E( \operatorname{nFIRES} )} })  = 0.735669 + 0.004732(\operatorname{KBDI\_April30}) + -1.1e-05(\operatorname{acresBurned})
$$

Exploring the confidence intervals
```{r}
temp.df <- data.frame(KBDI_April30 = 0, acresBurned = 518.07)
predict.glm(glm2, newdata = temp.df, type = "response", se.fit = TRUE)
```



Distribution of acres burned
```{r}
ggplot(temp, aes(x = acresBurned)) + 
  geom_histogram(aes(y = ..density..), binwidth = 1000, color = "darkblue", fill = "lightblue") +
  scale_x_continuous(breaks = seq(0, 35000, 4000)) +
  geom_density(alpha = .2, fill = 'blue') +
  geom_vline(aes(xintercept = mean(acresBurned)),
             color = "red", linetype = "solid", size = 1) +
  geom_vline(aes(xintercept = median(acresBurned)),
             color = "black", linetype = "dashed", size = 1)
```



Is acres burned statistically significant when standing alone? (p-value = 0.0657)
```{r}
temp <- seasonFires.sf %>%
  filter(Year >= 1993)
formula3 <- lm(nFIRES ~ acresBurned, data = temp)
glm3 <- glm(formula3, data = temp, family = poisson)

summary(glm3)

cor(temp$acresBurned,resid(glm3)) #0.04958
```



##Make correction to the models
1) set soil moisture deficit units to cm (SI units)
2) fit a negative binomial regression model instead of Poisson

Adjust data frames so that units are in cm
```{r}
seasonFires_cm.sf <- left_join(x = April30.df, y = seasonFires.sf, by = c("Year" = "Year")) %>%
  select("Year", "nFIRES", "Qlcm")
seasonFires.sf$nFIRES <- replace_na(seasonFires.sf$nFIRES, 0)
```

Model reflecting only soil moisture deficit
negative binomial regression
```{r}
nbr1 <- glm.nb(nFIRES ~ Qlcm, data = seasonFires_cm.sf)

#summary(nbr1)
```

```{r}
extract_eq(nbr1, use_coefs = TRUE, coef_digits = 4, fix_signs = FALSE)
```

$$
\log ({ \widehat{E( \operatorname{nFIRES} )} })  = 0.7515 + 0.1773(\operatorname{Qlcm})
$$

visualize the negative binomial regression model
```{r}
ggplot(seasonFires_cm.sf, aes(x = Qlcm, y = nFIRES)) +
  geom_point() +
  geom_smooth(method = "glm.nb") + #, formula = y ~ x,
              #method.args = list(family = poisson(link = "log"))) +
  ylab("Number of Fires in the ANF (May - July)") +
  xlab("Soil Moisture Deficit on April 30th (cm)") +
  #labs(
    #title = "Predicted Number of Fires During the Fire Season Based on April 30th Soil Moisture Deficit",
    #subtitle = "With a 95% Confidence Interval",
    #caption = "Period of Record: 1992 to 2018")
  theme_minimal()
```

Exploring predicted values and confidence intervals
```{r}
temp.df <- data.frame(Qlcm = 0)
predict.glm(nbr1, newdata = temp.df, type = "response", se.fit = TRUE)
```


Adjustments to set up multiple linear regression model
Error in the select statement. Explore further
```{r}
seasonFires_cm.sf <- left_join(x = seasonFires_cm.sf, y = burnedArea.sf, by = c("Year" = "forecastYear")) %>%
  select("seasonFires_cm.sf$Year":"seasonFires_cm.sf$percentBurned") %>%
  rename(nFIRES = nFIRES.x)
```

Multiple negative binominal regression model. Soil moisture deficit and prior acres burned.
Use temp dataframe because 1992 does not store all acres burned data.
```{r}
temp <- seasonFires_cm.sf %>%
  filter(Year >= 1993)
nbr2 <- glm.nb(nFIRES ~  Qlcm + acresBurned, data = temp)
```

add fitted values to dataframe to compare
```{r}
temp$nbr1_fit <- nbr1$fitted.values
temp$nbr2_fit <- nbr2$fitted.values
```


```{r}
extract_eq(nbr2, use_coefs = TRUE, coef_digits = 8, fix_signs = FALSE)
```

8 digits are used to show extent of acres burned beta coefficent
$$
\log ({ \widehat{E( \operatorname{nFIRES} )} })  = 0.75384833 + 0.18424609(\operatorname{Qlcm}) + -1.026e-05(\operatorname{acresBurned})
$$

Acres burned is not statistically significant to the model
```{r}
summary(nbr2)
```


