---
title: "Lightning Caused Fires in the ANF"
output: html_document
editor_options: 
  chunk_output_type: console
---

https://www.nifc.gov/nicc/predictive/outlooks/outlooks.htm
https://www.cpc.ncep.noaa.gov/products/predictions/90day/

## Keetch & Byram drought index computed from data collected at the Tallahassee airport

Original paper outlining the rationale and how to create it: https://www.srs.fs.usda.gov/pubs/rp/rp_se038.pdf

The Keetch-Byram Drought Index assesses the risk of fire by representing the net effect of evapotranspiration and precipitation in producing cumulative moisture deficiency in deep duff and upper soil layers. The index ranges from zero, the point of no moisture deficiency, to 800, the maximum drought that is possible. Units are 100's of inches. KBDI relates current and recent weather conditions to potential or expected fire behavior. It was originally developed for the Southeast United States and is based primarily on recent rainfall patterns. It is one of the only drought indices specifically developed to equate the effects of drought with potential fire behavior. 

For different soil types, the depth of soil required to hold 8 inches of moisture varies (loam = 30", clay = 25" and sand = 80"). A prolonged drought (high KBDI) influences fire intensity largely because more fuel is available for combustion (i.e. fuels have a lower moisture content). In addition, the drying of organic material in the soil can lead to greater difficulty in fire suppression.

High values of the KBDI indicate conditions favorable for the occurrence and spread of wildfires, but drought is not by itself a prerequisite for wildfires. Other weather factors, such as wind, temperature, relative humidity and atmospheric stability, play a major role in determining the actual fire danger.

NWS Tallahassee daily weather data:
https://www.ncdc.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:USW00093805/detail
https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt
Column explanations: https://docs.google.com/document/d/1q2WEpXndpMx9lUq-0ON63GojkaOzixrGyYEhI_xkPtw/edit?usp=sharing
AWND = Average daily wind speed (tenths of meters per second) 

### Import the summary of the day data and add columns to the data frame

Assign no rainfall on days with missing values.
```{r}
library(lubridate)
library(dplyr)
library(tidyr)

TLH.df <- read.csv(file = 'Data/TLH_Daily1940.csv',
                   stringsAsFactors = FALSE,
                   header = TRUE) %>%
  mutate(Date = as.Date(DATE)) %>%
  mutate(Year = year(Date), 
         month = month(Date, label = TRUE, abbr = TRUE),
         doy = yday(Date),
         MaxTemp = TMAX,
         MinTemp = TMIN,
         Rainfall24 = PRCP,
         Rainfall24 = replace_na(Rainfall24, 0),
         Rainfall24mm = Rainfall24 * 25.4)

TLH.df$MaxTemp[TLH.df$Date == "2005-07-08"] <- 96 # missing max temperature. Filled from weather underground data

sum(is.na(TLH.df$PRCP))
nrow(TLH.df)
sum(is.na(TLH.df$PRCP)) / nrow(TLH.df) * 100  # only 5 missing values [< .02% of all days]
```

### Compute daily values of the KBDI

Original paper outlining the rationale and how to create it: https://www.srs.fs.usda.gov/pubs/rp/rp_se038.pdf with correction identified in Alexander1992.pdf (paper found in Dropbox/Literature).

Step one: Compute net rainfall on each day. Units are inches.
```{r}
Rainfall24 <- TLH.df$Rainfall24
PR <- dplyr::lag(Rainfall24)
PR[1] <- 0

CumR <- 0
NetR <- numeric()

for(i in 1:length(Rainfall24)) {
  R24 <- Rainfall24[i]
  if (R24 == 0) {
    NetR[i] <- 0
    CumR <- 0
  } 
  else if(R24 > 0 & R24 <= .2) {
      CumR <- CumR + R24
      if (PR[i] > .2 | CumR > .2) NetR[i] <- R24
      else if (CumR > .2) NetR[i] <- CumR - .2
      else NetR[i] <- 0
    }
  else if (R24 > .2) {
      if (CumR <= .2) {
      NetR[i] <- CumR + R24 - .2
      CumR <- CumR + R24
      }
      else {
      NetR[i] <- R24
      CumR <- CumR + R24
      }
  }
}

TLH.df$NetR <- NetR
```

Step two: Compute daily drought index. Units of temperature are degrees F.
```{r}
Q <- 269  
R <- 59.23 # average annual rainfall for TLH

MaxTemp <- TLH.df$MaxTemp

Ql <- numeric()
DeltaQl <- numeric()
for(i in 1:length(Rainfall24)){
  DeltaQ <- (800 - Q) * (.968 * exp(.0486 * MaxTemp[i]) - 8.3) /(1 + 10.88 * exp(-.0441 * R)) * .001 
  Q <- ifelse(NetR[i] == 0,  Q + DeltaQ,  (Q + DeltaQ) - NetR[i] * 100)
  Q <- ifelse(Q < 0, 0, Q) 
  Ql <- c(Ql, Q)
  DeltaQl <- c(DeltaQl, DeltaQ)
}

TLH.df$Ql <- Ql
TLH.df$Qlm <- Ql * .254  # tenth of an inch to mm
TLH.df$DeltaQl <- DeltaQl
TLH.df$DroughtIndex <- floor(Ql/100)

TLH.df <- TLH.df %>%
 dplyr::filter(Year >= 1946 & Year <= 2019) # Only full years
range(TLH.df$Ql)
```

Note: There is a package to compute the standaridized precip-evapotranspiration index {SPEI}. Only good for monthly data. Same for PDSI.

### Trends

Make some trend plots. The second plot is statistically more realistic because it removes the temporal autocorrelations.
```{r}
library(ggplot2)

ggplot(TLH.df, aes(x = Date, y = Qlm, color = Qlm)) +
  geom_line() +
  scale_color_gradient2(low = "#FC8B93", mid = "#965784", high = "#D9DE6E", guide = FALSE) +
#  scale_y_reverse(breaks = seq(0, 200, by = 50), labels = c("Wet", 50, 100, 150, "Dry")) +
  ylab("") + xlab("") +
  geom_smooth(method = lm, se = FALSE) +
  facet_wrap(~ month, ncol = 12) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Daily soil moisture deficit (mm), Tallahassee, FL", 
       subtitle = "Amount of water needed to bring soil moisture to full capacity",
       caption = "Based on data from the NWSFO, Tallahassee, FL (1946-2019)") 

TLH.df %>%
  dplyr::group_by(month, Year) %>%
  dplyr::summarise(Avg = mean(Qlm)) %>%
  ggplot(aes(x = Year, y = Avg, color = Avg)) +
  geom_point() +  
  scale_color_gradient2(low = "#FC8B93", mid = "#965784", high = "#D9DE6E", guide = FALSE) +
  ylab("") + xlab("") +
  geom_smooth(method = lm) +
  facet_wrap(~ month, ncol = 12) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Monthly average soil moisture deficit (mm) by year, Tallahassee, FL", 
       subtitle = "Amount of water needed to bring soil moisture to full capacity",
       caption = "Based on data from the NWSFO, Tallahassee, FL (1946-2019)") 
```

Side-by-side daily distribution plots (early vs late) by month. 1943:1980, 1981:2019
Temperature distributions by epoch for days defined by the hot day/night seasons.
```{r}
TLH.df %>%
  mutate(Epoch = Year > 1980) %>%
  ggplot(aes(x = Qlm, color = Epoch)) +
#  geom_density(bw = 10, size = 1) +
  geom_freqpoly(size = 1, bins = 8) +
  scale_color_manual(labels = c("1943-1980", "1981-2019"), values = c("black", "sandybrown")) +
  scale_x_continuous(limits = c(0, 250), breaks = c(0, 100, 200)) +
  ylab("Number of days") + xlab("Daily soil moisture deficit (mm)") +
  facet_wrap(~ month, ncol = 12) +
#  coord_flip() +
  theme_minimal()
```

Repeat for using data from Apalachacola. https://www.ncdc.noaa.gov/  > I want to search for data at a particular location > DATA TOOLS > Final a Station

Linear trend model.
```{r}
summary(lm(Qlm ~ Date, data = TLH.df)) # this assumes daily Qlm are independent (they are certainly not)

library(broom)
library(quantreg)

Trends.df <- TLH.df %>% 
  group_by(Year, month) %>%
  summarize(AvgQlm = mean(Qlm)) %>%
  group_by(month) %>%
#  do(tidy(rq(AvgQlm ~ Year, tau = .5, data = .))) %>%
  do(tidy(lm(AvgQlm ~ Year, data = .))) %>%
  dplyr::filter(term == "Year")

Avg <- TLH.df %>%
  group_by(month) %>%
  summarize(AvgQlm = mean(Qlm)) %>%
  pull(AvgQlm)

cor(Trends.df$estimate, Avg) # positive indicating upward trends are occurring in months with higher drought index values

Avg <- TLH.df %>%
  group_by(month) %>%
  summarize(nYear = n_distinct(Year), 
            TotalPRCP = sum(PRCP, na.rm = TRUE),
            AvgMonthlyPRCP = TotalPRCP/nYear) %>%
  pull(AvgMonthlyPRCP)

cor(Trends.df$estimate, Avg)  # negative as expected since upward trends are occurring in months with less rainfall
```

Soil moisture deficits are increasing at .4 mm/year on average during April. Which amounts to 4 mm/decade.

What is the correlation between PRCP, TMAX and Qlm grouped by month?
```{r}
TLH.df %>%
  group_by(month) %>%
  summarize(rPRCP = cor(Qlm, PRCP, use = "complete"),
            rTMAX = cor(Qlm, TMAX, use = "complete"),
            rTMIN = cor(Qlm, TMIN, use = "complete"),
            rTAVG = cor(Qlm, TAVG, use = "complete"))
```

## Todo
Seasonal (fire season) temperature vs precipitation scatter plot. See TempVsPrecipSeasonal.jpeg
Create a character variable called `FireSeason`. Then group by that variable computing the average temp and total precipitation. 

Get SOI data and join with TLH.df.
```{r}
SOI.df <- read.csv(file = "https://www.ncdc.noaa.gov/teleconnections/enso/indicators/soi/data.csv",
                   skip = 1, header = TRUE) %>%
  mutate(Date = parse_date_time(as.character(Date), "ym"),
         Year = year(Date),
         Month = month(Date),
         month = month(Date, label = TRUE, abbr = TRUE),
         SOI = Value) %>%
  dplyr::select(Year, Month, month, SOI)

Joined.df <- TLH.df %>% 
  dplyr::filter(Year >= 1951) %>%
  group_by(Year, month) %>%
  summarize(AvgQlm = mean(Qlm)) %>%
  dplyr::select(Year, month, AvgQlm) %>%
  left_join(SOI.df, by = c("Year", "month"))

Joined.df %>%
  group_by(month) %>%
  do(tidy(lm(AvgQlm ~ Year + SOI, data = .))) %>%
  dplyr::filter(term == "Year")

Joined.df %>%
  group_by(month) %>%
  do(tidy(lm(AvgQlm ~ Year + SOI, data = .))) %>%
  dplyr::filter(term == "SOI")
```

SOI is positively correlated with moisture deficit. La Nina conditions (positive SOI) during winter leads to larger moisture deficits (higher Qlm).

In terms of frequency by Drought Index category. Proportion of the year in each drought category.
```{r}
TLH.df %>%
#  dplyr::filter(month == "May") %>%
  group_by(Year, DroughtIndex) %>%
  summarize(N = n()) %>%
  ggplot(aes(x = Year, y = N)) +
  geom_col(aes(fill = as.factor(DroughtIndex))) +
  scale_fill_viridis_d(name = "KBDI") +
  scale_x_continuous(name = "", breaks = seq(1948, 2019, 4)) +
  scale_y_reverse() +
  theme_minimal() +
  theme(axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank()) +
  guides(fill = guide_legend(reverse = TRUE))
```

Daily
```{r}
ggplot(TLH.df, aes(x = doy, y = Year, fill = Qlm)) +
  geom_tile() +
  scale_y_reverse(breaks = seq(1948, 2019, 4)) +
  scale_x_continuous(breaks = c(15,	46,	75,	106, 136, 167, 197, 228, 259, 289, 320, 350),
                     labels = month.abb, position = "top") +
  scale_fill_gradient2(name = "", low = "#FC8B93", mid = "#965784", high = "#D9DE6E") +
  ylab("") + xlab("") +
  theme_minimal() +
  ggtitle("Daily soil moisture deficit (mm), Tallahassee, FL", 
          subtitle = "Amount of water needed to bring soil moisture to full capacity") 

ggplot(TLH.df, aes(x = doy, y = Year, fill = factor(DroughtIndex))) +
  geom_tile() +
  scale_y_reverse(breaks = seq(1948, 2019, 4)) +
  scale_x_continuous(breaks = c(15,	46,	75,	106, 136, 167, 197, 228, 259, 289, 320, 350),
                     labels = month.abb, position = "top") +
  scale_fill_ordinal(name = "", direction = 1, alpha = .6) +
  ylab("") + xlab("") +
  theme_minimal() +
  guides(fill = guide_legend(reverse = TRUE)) +
  ggtitle("Daily drought category, Tallahassee, FL",
          subtitle = "7-6: Drought, 4-5: Dry, 1-3: Moist, 0: Saturated")
```

Number of days per year with KBDI above 650.
```{r}
library(MASS)

TLH.df %>%
  filter(Year != 2020) %>%
  group_by(Year) %>%
  summarize(nD = sum(Ql > 650)) %>%
  ggplot(aes(Year, nD)) +
  geom_point() +
  stat_smooth(method = "glm.nb",
              formula = y ~ x, 
              se = FALSE,
              col = "orange") 
```

## Spatial domain

Three regions of North Florida with extensive public lands, primarily the National Forests in Florida, were selected. Within these regions, a 10 km^2 hexagon grid was overlain in ArcMap 10.7 and only hexagons with >90% public lands were selected for analysis. These regions are some of the stateâ€™s largest intact natural areas where lightning-initiated fires are a seasonally common occurrence and wildfire size/distribution is not substantially influenced by confounding effects of urbanization, agricultural land or roadways. 

While such publicly managed natural areas deploy various proactive and reactive fire suppression resources, the incidence of large lightning-initiated fires is still largely a climactic and fuels-driven phenomenon. These landscapes are among the largest remaining semi-wild areas of fire-maintained longleaf pine savanna in the Southeast United States while the Ocala NF features the largest single complex of sand pine dominated scrub habitat in Florida. 

The resulting 528,987-hectare landscape footprint is imported as a simple feature data frame and corresponding lightning and wildfire point data are similarly imported from shapefiles uploaded to Dropbox.

Public land footprint. Download the footprint of North Florida public land hexagon border where the proportion of public land, (mostly USFS) is >= 90% of the area. We focus only on the Apalachicola National Forest.
```{r}
#download.file(url = "https://www.dropbox.com/s/wo52hwy6ol83nt8/NorthFloridaPublicLandHexagons10km.zip?dl=1",
#              destfile = "TempPubLand.zip")
#unzip("TempPubLand.zip")

library(sf)

LandHex.sf <- read_sf(dsn = "Data/NorthFloridaPublicLandHexagons10km.shp") %>%
  dplyr::filter(NAME == "APALACHICOLA")

library(tmap)

Airport.sf <- data.frame(Name = c("Regional Airport"), 
                       Latitude = c(30.39306),
                       Longitude = c(-84.35333)) %>%
  st_as_sf(coords = c("Longitude", "Latitude"),
           crs = 4326) %>%
  st_transform(crs = st_crs(LandHex.sf))

tmap_mode("view")
tm_shape(LandHex.sf) +
  tm_borders() +
tm_shape(Airport.sf) +
  tm_dots(size = .1, col = "darkgreen")
```

## Use {ggspatial} to make maps

https://github.com/paleolimbot/ggspatial/blob/master/vignettes/ggspatial.Rmd

On first use, a GIS will recognize much of the syntax of how plots are built from GIS language: there are layers, geometries, coordinate systems, and the ability to map attributes to the appearance of the layer (aesthetics). With {ggplot} version 3.0, `geom_sf()` and `coord_sf()` let users pass simple features (GIS layers from the {sf} package) objects as layers. Non-spatial data (data frames with XY or lon/lat coluns) and raster data are not well-supported in {ggplot2}, which is the gap filled by the {ggspatial} package.

```{r}
library(ggspatial)

LandHex.sf <- LandHex.sf %>%
  st_transform(crs = 4326)

ggplot() +
  annotation_map_tile(type = "osm") +
  layer_spatial(LandHex.sf)
```

Any spatial layer can be added to a `ggplot()` using `layer_spatial()` (well, any object from the **sf**, **sp**, or **raster** packages...). These layers will train the scales, meaning they will be visible unless you explicitly set the X or Y scale limits. Unlike `geom_` or `stat_` functions, `layer_spatial()` always takes its data first. Aesthetics can be passed for most types of objects, the exception being RGB rasters, which are more like backround images than data that should be mapped to a scale. Unlike `layer_spatial()`, `annotation_spatial()` layers never train the scales, so they can be used as a backdrop for other layers.



## Wildfires

Get Florida wildfire data. See `Get_Wildfires.Rmd` on Dropbox. These data were collected using funding from the U.S. Government and can be used without additional permissions or fees. If you use these data in a publication, presentation, or other research product please use the following citation:

Short, Karen C. 2017. Spatial wildfire occurrence data for the United States, 1992-2015 [FPA_FOD_20170508]. 4th Edition. Fort Collins, CO: Forest Service Research Data Archive. https://doi.org/10.2737/RDS-2013-0009.4

Abstract: This data publication contains a spatial database of wildfires that occurred in the United States from 1992 to 2015. It is the third update of a publication originally generated to support the national Fire Program Analysis (FPA) system. The wildfire records were acquired from the reporting systems of federal, state, and local fire organizations. The following core data elements were required for records to be included in this data publication: discovery date, final fire size, and a point location at least as precise as Public Land Survey System (PLSS) section (1-square mile grid). The data were transformed to conform, when possible, to the data standards of the National Wildfire Coordinating Group (NWCG). Basic error-checking was performed and redundant records were identified and removed, to the degree possible. The resulting product, referred to as the Fire Program Analysis fire-occurrence database (FPA FOD), includes 1.88 million geo-referenced wildfire records, representing a total of 140 million acres burned during the 24-year period.
```{r}
Fires.sf <- st_read(dsn = "Data/FL_Fires",
                    layer = "FL_Fires")  %>%
  st_transform(crs = st_crs(LandHex.sf)) %>%
  dplyr::filter(STAT_CAU_1 == "Lightning") %>%
  st_intersection(LandHex.sf)

tm_shape(LandHex.sf) +
  tm_borders() +
tm_shape(Fires.sf) +
  tm_dots(size = .03) +
tm_shape(Airport.sf) +
  tm_dots(size = .1, col = "darkgreen")

Fires.sf <- Fires.sf %>%
  mutate(Year = year(DISCOVERY_),
         Month = month(DISCOVERY_),
         Day = day(DISCOVERY_),
         YDay = yday(DISCOVERY_),
         YDayF = factor(YDay, levels = as.character(1:366))) %>%
  dplyr::select(Year, Month, Day, YDay, YDayF, FIRE_SIZE, FIRE_SIZE_)
```

Make fire size an ordered factor and create a model that predicts the probability by size category similar to EF rating.
```{r}
Fires.sf %>%
  group_by(FIRE_SIZE_) %>%
  summarize(nFires = n(),
            Range1 = range(FIRE_SIZE)[1],
            Range2 = range(FIRE_SIZE)[2])
```

```{r}
Fires.sf %>%
  as.data.frame() %>%
  mutate(MonthF = factor(month.name[Month], levels = month.name, ordered = TRUE)) %>%
  group_by(MonthF, .drop = FALSE) %>%
  summarize(nF = n()) %>% 
ggplot(aes(x = MonthF, y = nF)) +
  geom_col(col = "gray70", fill = "gray70") +
  coord_flip() + xlab("") + ylab("") +
  theme_minimal() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank()
    )

Yearly <- 
  Fires.sf %>%
  as.data.frame() %>%
  filter(Month %in% c(5, 6, 7)) %>%
  mutate(YearF = factor(Year, levels = as.character(1992:2015), ordered = TRUE)) %>%
  group_by(YearF, .drop = FALSE) %>%
  summarize(nF = n()) %>%
  mutate(Year = 1992:2015)

ggplot(Yearly, aes(x = YearF, y = nF)) +
  geom_point()

PSDI <- TLH.df %>%
  dplyr::filter(Year >= 1992 & Year <= 2015) %>%
  dplyr::filter(month == "Apr") %>%
  group_by(Year) %>%
  summarize(KBDI = last(Qlm))

SOI <- SOI.df %>%
  dplyr::filter(Year >= 1992 & Year <= 2015) %>%
  dplyr::filter(month == "Apr") %>%
  pull(SOI)

df <- data.frame(Year = PSDI$Year, nFires = Yearly$nF, KBDI = PSDI$KBDI, SOI = SOI)
```

Correlation by day of Month during April.
```{r}
TLH.df %>%
  dplyr::filter(Year >= 1992 & Year <= 2015) %>%
#  dplyr::filter(month == "Apr") %>%
#  mutate(Day = day(Date)) %>%
  group_by(doy, Year) %>%
  summarize(KBDI = Qlm) %>%
  dplyr::filter(doy != 366) %>%
  group_by(doy) %>%
  summarize(r = cor.test(KBDI, Yearly$nF)$estimate,
            rLo = cor.test(KBDI, Yearly$nF, conf.level = .9)$conf.int[1],
            rHi = cor.test(KBDI, Yearly$nF, conf.level = .9)$conf.int[2]) %>%
  ggplot(aes(x = doy, y = r)) +
  geom_ribbon(aes(ymin = rLo, ymax = rHi), fill = "gray90") +
  geom_point() +
  geom_line() +
  geom_segment(lineend = "round", aes(x = 121, xend = 213, y = .9, yend = .9), size = 3, col = "red") +
  scale_y_continuous(limits = c(-1, 1)) +
  scale_x_continuous(breaks = c(1,	32,	60,	91, 121, 152, 182, 213, 244, 274, 305, 335),
                     labels = month.abb, position = "top") +
  theme_minimal()
```

Negative binomial regression.
```{r}
library(MASS)

var(df$nFires)/mean(df$nFires)
exp(coef(glm.nb(nFires ~ 1, data = df)))
exp(coef(glm.nb(nFires ~ KBDI + SOI, data = df))) # 1.189 or 19% increase in the risk of a wildfire per cm increase in soil moisture deficit


model <- glm.nb(nFires ~ KBDI, data = df)

ggplot(df, aes(x = KBDI, y = nFires)) +
  geom_point() + 
  geom_line(aes(y = fitted(model))) +
  ylab("Number of Fires (May-July)") + xlab("Drought Index (April)") +
  theme_minimal()
```

Use the {brms} and {tidybayes} packages to get posterior distributions. See https://www.youtube.com/watch?v=wbzfqh_3LyM&list=PLCrWEzJgSUqzI3goQEAKkDsHg72inmqbe&index=20&t=0s

Also hot-days.Rmd, PredictTorFreqByEF.Rmd
