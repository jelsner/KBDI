---
title: "Lightning Caused Fires in the ANF"
output: html_document
editor_options: 
  chunk_output_type: console
---

## Keetch & Byram drought index computed from data collected at the Tallahassee airport

The Keetch-Byram Drought Index assesses the risk of fire by representing the net effect of evapotranspiration and precipitation in producing cumulative moisture deficiency in deep duff and upper soil layers. The index ranges from zero, the point of no moisture deficiency, to 800, the maximum drought that is possible. Keetch Byram Drought Index (KBDI) is a mathematical system for relating current and recent weather conditions to potential or expected fire behavior. KBDI was originally developed for the Southeast United States and is based primarily on recent rainfall patterns. It is one of the only drought indices specifically developed to equate the effects of drought with potential fire behavior. KBDI provides a number ranging from 0 to 800 that describes the moisture deficit of the top eight inches of soil. A drought index of 0 defines the point where there is no moisture deficiency and 800 defines maximum drought.

For different soil types, the depth of soil required to hold 8 inches of moisture varies (loam=30", clay=25" and sand=80"). A prolonged drought (high KBDI) influences fire intensity largely because more fuel is available for combustion (i.e. fuels have a lower moisture content). In addition, the drying of organic material in the soil can lead to increased difficulty in fire suppression.

High values of the KBDI indicate conditions favorable for the occurrence and spread of wildfires, but drought is not by itself a prerequisite for wildfires. Other weather factors, such as wind, temperature, relative humidity and atmospheric stability, play a major role in determining the actual fire danger.

NWS Tallahassee daily weather data:
https://www.ncdc.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:USW00093805/detail
https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt
Column explanations: https://docs.google.com/document/d/1q2WEpXndpMx9lUq-0ON63GojkaOzixrGyYEhI_xkPtw/edit?usp=sharing
AWND = Average daily wind speed (tenths of meters per second) 

### Import the data and add columns to the data frame

Assign 0 rainfall to days with missing values.
```{r}
library(lubridate)
library(dplyr)
library(tidyr)

TLH.df <- read.csv(file = 'Data/TLH_Daily1940.csv',
                   stringsAsFactors = FALSE,
                   header = TRUE) %>%
  mutate(Date = as.Date(DATE)) %>%
  mutate(Year = year(Date), 
         month = month(Date, label = TRUE, abbr = TRUE),
         doy = yday(Date),
         MaxTemp = TMAX,
         MinTemp = TMIN,
         Rainfall24 = PRCP,
         Rainfall24 = replace_na(Rainfall24, 0),
         Rainfall24mm = Rainfall24 * 25.4)

TLH.df$MaxTemp[TLH.df$Date == "2005-07-08"] <- 96

sum(is.na(TLH.df$PRCP))
nrow(TLH.df)
sum(is.na(TLH.df$PRCP)) / nrow(TLH.df) * 100  # only 5 missing values [< .02% of all days]
```

### Compute daily KBDI

Original paper outlining the rationale and how to create it: https://www.srs.fs.usda.gov/pubs/rp/rp_se038.pdf with correction in Alexander1992.pdf in Dropbox/Literature.

Step one: Compute net rainfall.
```{r}
Rainfall24 <- TLH.df$Rainfall24
PR <- dplyr::lag(Rainfall24)
PR[1] <- 0

CumR <- 0
NetR <- numeric()

for(i in 1:length(Rainfall24)) {
  R24 <- Rainfall24[i]
  if ( R24 == 0) {
    NetR[i] <- 0
    CumR <- 0
  } 
  else if( R24 > 0 & R24 <= .2) {
      CumR <- CumR + R24
      if (PR[i] > .2 | CumR > .2) NetR[i] <- R24
      else if (CumR > .2) NetR[i] <- CumR - .2
      else NetR[i] <- 0
    }
  else if ( R24 > .2) {
      if (CumR <= .2) {
      NetR[i] <- CumR + R24 - .2
      CumR <- CumR + R24
      }
      else {
      NetR[i] <- R24
      CumR <- CumR + R24
      }
  }
}

TLH.df$NetR <- NetR
```

Step two: Compute drought index.
```{r}
Q <- 269
R <- 59.23

MaxTemp <- TLH.df$MaxTemp

Ql <- numeric()
DeltaQl <- numeric()
for(i in 1:length(Rainfall24)){
  DeltaQ <- (800 - Q) * (.968 * exp(.0486 * MaxTemp[i]) - 8.3) /(1 + 10.88 * exp(-.0441 * R)) * .001 
  Q <- ifelse(NetR[i] == 0,  Q + DeltaQ,  (Q + DeltaQ) - NetR[i] * 100)
  Q <- ifelse(Q < 0, 0, Q) 
  Ql <- c(Ql, Q)
  DeltaQl <- c(DeltaQl, DeltaQ)
}

TLH.df$Ql <- Ql
TLH.df$Qlm <- Ql * .254  # tenth of an inch to mm
TLH.df$DeltaQl <- DeltaQl
TLH.df$DroughtIndex <- floor(Ql/100)

TLH.df <- TLH.df %>%
 dplyr::filter(Year >= 1946 & Year <= 2019) # Only full years
range(TLH.df$Ql)
```

Package to compute the standaridized precip-evapotranspiration index {SPEI}. Only good for monthly data. Same for PDSI.

### Soil moisture data from ESA

### Trends

```{r}
library(ggplot2)

ggplot(TLH.df, aes(x = Date, y = Qlm, color = Qlm)) +
  geom_line() +
  scale_color_gradient2(low = "#FC8B93", mid = "#965784", high = "#D9DE6E", guide = FALSE) +
#  scale_y_reverse(breaks = seq(0, 200, by = 50), labels = c("Wet", 50, 100, 150, "Dry")) +
  ylab("") + xlab("") +
  geom_smooth(method = lm, se = FALSE) +
  facet_wrap(~ month, ncol = 12) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Daily soil moisture deficit (mm), Tallahassee, FL", 
       subtitle = "Amount of water needed to bring soil moisture to full capacity",
       caption = "Based on data from the NWSFO, Tallahassee, FL (1946-2019)") 
```

Linear trend model.
```{r}
summary(lm(Qlm ~ Date, data = TLH.df)) # this assumes daily Qlm are independent (they are certainly not)

library(broom)
library(quantreg)

Trends.df <- TLH.df %>% 
  group_by(Year, month) %>%
  summarize(AvgQlm = mean(Qlm)) %>%
  group_by(month) %>%
#  do(tidy(rq(AvgQlm ~ Year, tau = .5, data = .))) %>%
  do(tidy(lm(AvgQlm ~ Year, data = .))) %>%
  dplyr::filter(term == "Year")

Avg <- TLH.df %>%
  group_by(month) %>%
  summarize(AvgQlm = mean(Qlm)) %>%
  pull(AvgQlm)

cor(Trends.df$estimate, Avg)

Avg <- TLH.df %>%
  group_by(month) %>%
  summarize(nYear = n_distinct(Year), 
            TotalPRCP = sum(PRCP, na.rm = TRUE),
            AvgMonthlyPRCP = TotalPRCP/nYear) %>%
  pull(AvgMonthlyPRCP)

cor(Trends.df$estimate, Avg)
```

Soil moisture deficits are increasing at .4 mm/year on average during April. Which amounts to 4 mm/decade.

What is the correlation between PRCP, TMAX and Qlm grouped by month?
```{r}
TLH.df %>%
  group_by(month) %>%
  summarize(rPRCP = cor(Qlm, PRCP, use = "complete"),
            rTMAX = cor(Qlm, TMAX, use = "complete"),
            rTMIN = cor(Qlm, TMIN, use = "complete"),
            rTAVG = cor(Qlm, TAVG, use = "complete"))
```

Get SOI data and join with TLH.df.
```{r}
SOI.df <- read.csv(file = "https://www.ncdc.noaa.gov/teleconnections/enso/indicators/soi/data.csv",
                   skip = 1, header = TRUE) %>%
  mutate(Date = parse_date_time(as.character(Date), "ym"),
         Year = year(Date),
         Month = month(Date),
         month = month(Date, label = TRUE, abbr = TRUE),
         SOI = Value) %>%
  dplyr::select(Year, Month, month, SOI)

Joined.df <- TLH.df %>% 
  dplyr::filter(Year >= 1951) %>%
  group_by(Year, month) %>%
  summarize(AvgQlm = mean(Qlm)) %>%
  dplyr::select(Year, month, AvgQlm) %>%
  left_join(SOI.df, by = c("Year", "month"))

Joined.df %>%
  group_by(month) %>%
  do(tidy(lm(AvgQlm ~ Year + SOI, data = .))) %>%
  dplyr::filter(term == "Year")

Joined.df %>%
  group_by(month) %>%
  do(tidy(lm(AvgQlm ~ Year + SOI, data = .))) %>%
  dplyr::filter(term == "SOI")
```

SOI is positively correlated with moisture deficit. La Nina conditions (positive SOI) during winter leads to larger moisture deficits (higher Qlm).

It terms of frequency by Drought Index category.
```{r}
TLH.df %>%
#  dplyr::filter(month == "May") %>%
  group_by(Year, DroughtIndex) %>%
  summarize(N = n()) %>%
  ggplot(aes(x = Year, y = N)) +
  geom_col(aes(fill = as.factor(DroughtIndex))) +
  scale_fill_viridis_d(name = "KBDI") +
  scale_x_continuous(name = "", breaks = seq(1948, 2019, 4)) +
  scale_y_reverse() +
  theme_minimal() +
  theme(axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank()) +
  guides(fill = guide_legend(reverse = TRUE))
```

Daily
```{r}
ggplot(TLH.df, aes(x = doy, y = Year, fill = Qlm)) +
  geom_tile() +
  scale_y_reverse(breaks = seq(1948, 2019, 4)) +
  scale_x_continuous(breaks = c(15,	46,	75,	106, 136, 167, 197, 228, 259, 289, 320, 350),
                     labels = month.abb, position = "top") +
  scale_fill_gradient2(name = "", low = "#FC8B93", mid = "#965784", high = "#D9DE6E") +
  ylab("") + xlab("") +
  theme_minimal() +
  ggtitle("Daily soil moisture deficit (mm), Tallahassee, FL", 
          subtitle = "Amount of water needed to bring soil moisture to full capacity") 

ggplot(TLH.df, aes(x = doy, y = Year, fill = factor(DroughtIndex))) +
  geom_tile() +
  scale_y_reverse(breaks = seq(1948, 2019, 4)) +
  scale_x_continuous(breaks = c(15,	46,	75,	106, 136, 167, 197, 228, 259, 289, 320, 350),
                     labels = month.abb, position = "top") +
  scale_fill_ordinal(name = "", direction = 1, alpha = .6) +
  ylab("") + xlab("") +
  theme_minimal() +
  guides(fill = guide_legend(reverse = TRUE))
```

Number of days per year with KBDI above 650.
```{r}
library(MASS)

TLH.df %>%
  filter(Year != 2020) %>%
  group_by(Year) %>%
  summarize(nD = sum(Ql > 650)) %>%
  ggplot(aes(Year, nD)) +
  geom_point() +
  stat_smooth(method = "glm.nb",
              formula = y ~ x, 
              se = FALSE,
              col = "orange") 
```

## Spatial domain

Three regions of North Florida with extensive public lands, primarily the National Forests in Florida, were selected. Within these regions, a 10 km^2 hexagon grid was overlain in ArcMap 10.7 and only hexagons with >90% public lands were selected for analysis. These regions are some of the stateâ€™s largest intact natural areas where lightning-initiated fires are a seasonally common occurrence and wildfire size/distribution is not radically influenced by confounding effects of urbanization, agricultural land or roadways. 

While such publicly managed natural areas deploy various proactive and reactive fire suppression resources, the incidence of large lightning-initiated fires is still largely a climactic and fuels-driven phenomenon. These landscapes are among the largest remaining semi-wild areas of fire-maintained longleaf pine savanna in the Southeast United States while the Ocala NF features the largest single complex of sand pine dominated scrub habitat in Florida. 

The resulting 528,987-hectare landscape footprint is imported as a simple feature data frame and corresponding lightning and wildfire point data are similarly imported from shapefiles uploaded to Dropbox.

Public land footprint. Download the footprint of North Florida public land hexagon border where the proportion of public land, (mostly USFS) is >= 90% of the area.
```{r}
#download.file(url = "https://www.dropbox.com/s/wo52hwy6ol83nt8/NorthFloridaPublicLandHexagons10km.zip?dl=1",
#              destfile = "TempPubLand.zip")
#unzip("TempPubLand.zip")

library(sf)

LandHex.sf <- read_sf(dsn = "Data/NorthFloridaPublicLandHexagons10km.shp") %>%
  dplyr::filter(NAME == "APALACHICOLA")

library(tmap)

tmap_mode("view")
tm_shape(LandHex.sf) +
  tm_borders()
```

## Wildfires

Get Florida wildfire data. See `Get_Wildfires.Rmd` on Dropbox. These data were collected using funding from the U.S. Government and can be used without additional permissions or fees. If you use these data in a publication, presentation, or other research product please use the following citation:

Short, Karen C. 2017. Spatial wildfire occurrence data for the United States, 1992-2015 [FPA_FOD_20170508]. 4th Edition. Fort Collins, CO: Forest Service Research Data Archive. https://doi.org/10.2737/RDS-2013-0009.4

Abstract:This data publication contains a spatial database of wildfires that occurred in the United States from 1992 to 2015. It is the third update of a publication originally generated to support the national Fire Program Analysis (FPA) system. The wildfire records were acquired from the reporting systems of federal, state, and local fire organizations. The following core data elements were required for records to be included in this data publication: discovery date, final fire size, and a point location at least as precise as Public Land Survey System (PLSS) section (1-square mile grid). The data were transformed to conform, when possible, to the data standards of the National Wildfire Coordinating Group (NWCG). Basic error-checking was performed and redundant records were identified and removed, to the degree possible. The resulting product, referred to as the Fire Program Analysis fire-occurrence database (FPA FOD), includes 1.88 million geo-referenced wildfire records, representing a total of 140 million acres burned during the 24-year period.
```{r}
Fires.sf <- st_read(dsn = "Data/FL_Fires",
                    layer = "FL_Fires")  %>%
  st_transform(crs = st_crs(LandHex.sf)) %>%
  dplyr::filter(STAT_CAU_1 == "Lightning") %>%
  st_intersection(LandHex.sf)

tm_shape(LandHex.sf) +
  tm_borders() +
tm_shape(Fires.sf) +
  tm_dots(size = .03)

Fires.sf <- Fires.sf %>%
  mutate(Year = year(DISCOVERY_),
         Month = month(DISCOVERY_),
         Day = day(DISCOVERY_),
         YDay = yday(DISCOVERY_),
         YDayF = factor(YDay, levels = as.character(1:366))) %>%
  dplyr::select(Year, Month, Day, YDay, YDayF, FIRE_SIZE, FIRE_SIZE_)
```

Make fire size an ordered factor and create a model that predicts the probability by size category similar to EF rating.
```{r}
Fires.sf %>%
  group_by(FIRE_SIZE_) %>%
  summarize(nFires = n(),
            Range1 = range(FIRE_SIZE)[1],
            Range2 = range(FIRE_SIZE)[2])
```

```{r}
Fires.sf %>%
  as.data.frame() %>%
  mutate(MonthF = factor(month.name[Month], levels = month.name, ordered = TRUE)) %>%
  group_by(MonthF, .drop = FALSE) %>%
  summarize(nF = n()) %>% 
ggplot(aes(x = MonthF, y = nF)) +
  geom_col(col = "gray70", fill = "gray70") +
  coord_flip() + xlab("") + ylab("") +
  theme_minimal() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank()
    )

Yearly <- 
  Fires.sf %>%
  as.data.frame() %>%
  filter(Month %in% c(5, 6, 7)) %>%
  mutate(YearF = factor(Year, levels = as.character(1992:2015), ordered = TRUE)) %>%
  group_by(YearF, .drop = FALSE) %>%
  summarize(nF = n())

ggplot(Yearly, aes(x = YearF, y = nF)) +
  geom_point()

PSDI <- TLH.df %>%
  dplyr::filter(Year >= 1992 & Year <= 2015) %>%
  dplyr::filter(month == "Apr") %>%
  group_by(Year) %>%
  summarize(KBDI = last(Qlm))

SOI <- SOI.df %>%
  dplyr::filter(Year >= 1992 & Year <= 2015) %>%
  dplyr::filter(month == "Apr") %>%
  pull(SOI)

df <- data.frame(Year = PSDI$Year, nFires = Yearly$nF, KBDI = PSDI$KBDI, SOI = SOI)
```

Negative binomial regression.
```{r}
library(MASS)

var(df$nFires)/mean(df$nFires)
exp(coef(glm.nb(nFires ~ 1, data = df)))
exp(coef(glm.nb(nFires ~ KBDI + SOI, data = df))) # 1.189 or 19% increase in the risk of a wildfire per cm increase in soil moisture deficit


model <- glm.nb(nFires ~ KBDI, data = df)

ggplot(df, aes(x = KBDI, y = nFires)) +
  geom_point() + 
  geom_line(aes(y = fitted(model))) +
  ylab("Number of Fires (May-July)") + xlab("Drought Index (April)") +
  theme_minimal()
```
