---
title: "Keetch-Byram Drought Index"
output: html_document
editor_options: 
  chunk_output_type: console
---

Original paper outlining the rationale and how to create it: https://www.srs.fs.usda.gov/pubs/rp/rp_se038.pdf

## Keetch & Byram drought index

Rainfall. Data from Figure 1 of Keetch & Byram 1968.
```{r}
Rainfall24 <- c(0, 0, .66, 0, .23, 0, .16, .09, 0, 0, .08, .03, 0, .22, 0, .21, 0, 0, 0, .01, 0, 0, 0, 0, 0, 0, 0, 0, .25, .16)

CumR <- 0
NetR <- numeric()

for(i in 1:30) {
  R24 <- Rainfall24[i]
  PR <- ifelse(i == 1, NA, Rainfall24[i-1])
  
  if ( R24 == 0) {
    NetR[i] <- 0
    CumR <- 0
  } 
  else if( R24 > 0 & R24 <= .2) {
      CumR <- CumR + R24
      if (PR > .2 | CumR > .2) NetR[i] <- R24
      else if (CumR > .2) NetR[i] <- CumR - .2
      else NetR[i] <- 0
      print(c(CumR, PR, R24, NetR[i]))
    }
  
  else if ( R24 > .2) {
      if (CumR <= .2) {
      NetR[i] <- CumR + R24 - .2
      CumR <- CumR + R24
      }
      else {
      NetR[i] <- R24
      CumR <- CumR + R24
      }
  }
}

NetR

C3 <- NetR

Column3 <- c(0, 0, .46, 0, .03, 0, 0, .05, 0, 0, 0, 0, 0, .02, 0, .01, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, .05, .16)

cor(C3, Column3) #Check the match
```

Air temperature. Data from Figure 1 of Keetch & Byram 1968.
```{r}
MaxTemp <- c(79, 75, 70, 76, 79, 84, 65, 66, 83, 70, 67, 65, 76, 69, 65, 75, 78, 85, 88, 79, 69, 75, 84, 89, 93, 92, 96, 91, 78, 83)

Column4 <- MaxTemp
```

Drought factor equation. Eq. 18 from Keetch & Byram, 1968. Q: Drought Index Yesterday (initial value), MaxTemp: Today's high temperature (F) and R is annual average rainfall in inches.
```{r}
Q <- 164
R <- 42
MaxT <- 79

( DeltaQ <- (800 - Q) * (.968 * exp(.0486 * MaxT) - 8.30) /(1 + 10.88 * exp(-.0441 * R)) * .001 )
```

Implemented for each day.
```{r}
Q <- 164
Ql <- numeric()
DeltaQl <- numeric()
for(i in 1:30){
  DeltaQ <- (800 - Q) * (.968 * exp(.0486 * MaxTemp[i]) - 8.30) /(1 + 10.88 * exp(-.0441 * R)) * .001 
  Q <- ifelse(NetR[i] == 0,  Q + DeltaQ,  (Q + DeltaQ) - NetR[i] * 100)
  Ql <- c(Ql, Q)
  DeltaQl <- c(DeltaQl, DeltaQ)
}
Ql
DeltaQl

C5 <- Ql - DeltaQl
C6 <- DeltaQl
C7 <- Ql

DroughtIndex <- floor(Ql/100)
```

Check how well they match the Figure 1.
```{r}
Column5 <- c(164, 174, 136, 142, 148, 159, 173, 172, 176, 190, 196, 200, 204, 210, 215, 218, 226, 235, 248, 263, 271, 276, 283, 295, 311, 328, 345, 365, 373, 364)
cor(C5, Column5)
Column6 <- c(10, 8, 6, 9, 11, 14, 4, 4, 14, 6, 4, 4, 8, 5, 4, 8, 9, 13, 15, 8, 5, 7, 12, 16, 17, 17, 20, 13, 7, 10)
cor(C6, Column6)
Column7 <- c(174, 182, 142, 151, 159, 173, 177, 176, 190, 196, 200, 204, 212, 215, 219, 226, 235, 248, 263, 271, 276, 283, 295, 311, 328, 345, 365, 378, 380, 374)
cor(C7, Column7)
```

## Repeat for a month of data from the Tallahassee airport.
https://www.ncdc.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:USW00093805/detail

https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt
Column explanations: https://docs.google.com/document/d/1q2WEpXndpMx9lUq-0ON63GojkaOzixrGyYEhI_xkPtw/edit?usp=sharing

AWND = Average daily wind speed (tenths of meters per second)

Import the data.
```{r}
library(lubridate)
library(dplyr)
library(tidyr)

TLH.df <- read.csv(file = 'TLH_SOD1892.csv',
                   stringsAsFactors = FALSE,
                   header = TRUE) %>%
      filter(STATION == 'USW00093805') %>%
      mutate(Date = as.Date(DATE)) %>%
      mutate(Year = year(Date), 
             Month = month(Date), 
             Day = day(Date),
             doy = yday(Date)) %>%
#      filter(Year == 2017 & Month == 5) %>%
      filter(Date >= as.Date("1941-01-01")) %>%
      dplyr::select(Date, Year, Month, Day, doy, MaxTemp = TMAX, MinTemp = TMIN, Rainfall24 = PRCP) %>%
      mutate(Rainfall24 = replace_na(Rainfall24, 0),
             Rainfall24mm = Rainfall24 * 25.4)

TLH.df$MaxTemp[TLH.df$Date == "2005-07-08"] <- 96
```

Current index by county in FL: http://currentweather.freshfromflorida.com/kbdi_index.html

Leon County, May 1, 2017: http://currentweather.freshfromflorida.com/kbdi/cgi-bin/get_archive_v2.py?date=2017-05-01 (only past three years are available) 
```{r}
Q <- 429
```

Annual avg precipitation for Tallahassee, FL: https://www.usclimatedata.com/climate/tallahassee/florida/united-states/usfl0479 : 59.23 in.
```{r}
R <- 59.23
```

Step one: Compute net rainfall.
```{r}
Rainfall24 <- TLH.df$Rainfall24
PR <- dplyr::lag(Rainfall24)
PR[1] <- 0

CumR <- 0
NetR <- numeric()

for(i in 1:length(Rainfall24)) {
  R24 <- Rainfall24[i]
  
  if ( R24 == 0) {
    NetR[i] <- 0
    CumR <- 0
  } 
  else if( R24 > 0 & R24 <= .2) {
      CumR <- CumR + R24
      if (PR[i] > .2 | CumR > .2) NetR[i] <- R24
      else if (CumR > .2) NetR[i] <- CumR - .2
      else NetR[i] <- 0
    }
  
  else if ( R24 > .2) {
      if (CumR <= .2) {
      NetR[i] <- CumR + R24 - .2
      CumR <- CumR + R24
      }
      else {
      NetR[i] <- R24
      CumR <- CumR + R24
      }
  }
}

TLH.df$NetR <- NetR
```

Step two: Compute drought index.
```{r}
Q <- 269
R <- 59.23

MaxTemp <- TLH.df$MaxTemp

Ql <- numeric()
DeltaQl <- numeric()
for(i in 1:length(Rainfall24)){
  DeltaQ <- (800 - Q) * (.968 * exp(.0486 * MaxTemp[i]) - 8.3) /(1 + 10.88 * exp(-.0441 * R)) * .001 
  Q <- ifelse(NetR[i] == 0,  Q + DeltaQ,  (Q + DeltaQ) - NetR[i] * 100)
  Q <- ifelse(Q < 0, 0, Q) 
  Ql <- c(Ql, Q)
  DeltaQl <- c(DeltaQl, DeltaQ)
}
#Ql
#DeltaQl

TLH.df$Ql <- Ql
TLH.df$DeltaQl <- DeltaQl
TLH.df$DroughtIndex <- floor(Ql/100)

range(TLH.df$Ql)
```

```{r}
library(ggplot2)

ggplot(TLH.df, aes(x = Date, y = Ql)) +
  geom_line() +
  scale_y_continuous(limits = c(0, 800)) +
  ylab("") + xlab("") +
  geom_quantile(quantiles = c(.25, .5, .75, .9)) +
  theme_minimal() +
  ggtitle("Keetch-Byram Drought Index", 
          subtitle = "Based on data from the NWSFO, Tallahassee, FL  (2012-2018)")
```

## Calendar map of KDBI

Functions for calendar heat map.
```{r}
cal <- function(dt) {
    # Reads a date object and returns a tuple (weekrow, daycol)
    # where weekrow starts at 1 and daycol starts at 1 for Sunday
    #http://swingleydev.org/blog/tag/r/
    year <- year(dt)
    month <- month(dt)
    day <- day(dt)
    wday_first <- wday(ymd(paste(year, month, 1, sep = '-'), quiet = TRUE))
    offset <- 7 + (wday_first - 2)
    weekrow <- ((day + offset) %/% 7) - 1
    daycol <- (day + offset) %% 7

    c(weekrow, daycol)
}
weekrow <- function(dt) {
    cal(dt)[1]
}
daycol <- function(dt) {
    cal(dt)[2]
}
vweekrow <- function(dts) {
    sapply(dts, weekrow)
}
vdaycol <- function(dts) {
    sapply(dts, daycol)
}

TLH.df <- read.csv(file = 'TLH_Daily1940.csv',
                   stringsAsFactors = FALSE,
                   header = TRUE) %>%
  mutate(Date = as.Date(DATE)) %>%
  filter(Date >= as.Date("1990-08-01")) %>%
  mutate(Year = year(Date), 
         month = month(Date, label = TRUE, abbr = TRUE),
         weekrow = vweekrow(Date),
         daycol = vdaycol(Date))

ggplot(TLH.df) + 
    aes(daycol, weekrow, fill = TMAX) + 
  geom_tile(colour = "white") + 
  scale_y_reverse() +
  facet_grid(Year ~ month) + 
  scale_fill_gradient(low = "green", high = "red",
                      name = "°F") +
    theme_minimal() +
  theme(axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        strip.text  = element_text(angle=0),
        strip.text.y = element_text(angle=0),
        panel.spacing = unit(0, "lines")) +
  ggtitle("Official Daily High Temperature in Tallahassee, Florida", 
          subtitle = "Every day since I arrived")
```

## Florida USNG
https://usngcenter.org/portfolio-item/usng-gis-data/
```{r}
unzip("FL_USNG.zip")

FL16 <- st_read(dsn = "FL_USNG_UTM16.shp")
```

Download the POSITIVE lightning strikes within the PubLand footprint for the time period:
```{r}
download.file(url = "https://www.dropbox.com/s/82vn5u0r0n99xrb/NorthFloridaLightningHexagonsPos.zip?dl=1",
              destfile = "TempLightning.zip")
unzip("TempLightning.zip")
Lightning.sf <- st_read(dsn = "NorthFloridaLightningHexagonsPos.shp") %>%
  st_transform(crs = st_crs(FL16))
head(Lightning.sf)
```

Aggregate lightning strikes to grids.
```{r}
library(tidyverse)
library(lubridate)

LG.sf <- Lightning.sf %>%
           mutate(Mo = month(Date)) %>%
           filter(Mo %in% c(6, 7, 8))
LG.sf <- aggregate(LG.sf[, "OBJECTID"], 
                   by = FL16, 
                   FUN = length) %>%
    rename(Count = OBJECTID) %>%
  filter(!is.na(Count))

library(tmap)

tmap_mode("view")
tm_shape(LG.sf) +
  tm_polygons(col = "Count", alpha = .6, border.col = "transparent")
```

## Wildfires

Get Florida wild fire data. See `Get_Wildfires.Rmd` on Dropbox.
```{r}
library(sf)

FL_Fires.sf <- st_read(dsn = "FL_Fires")
```

Make a map
```{r}
library(USAboundaries)

FLcty <- us_counties(state = "FL")

library(tmap)

tm_shape(FLcty) +
  tm_borders() +
tm_shape(FL_Fires.sf) +
  tm_dots()
```

Tallahassee airport location: Lat: 30.3931° N Lon: -84.3533° W
```{r}
TLH.df <- data.frame(Longitude = -84.3533, Latitude = 30.3931)
TLH.sf <- st_as_sf(TLH.df,
                   coords = c("Longitude", "Latitude"),
                   crs = 4326) %>%
  st_transform(crs = st_crs(FL_Fires.sf))
TLH_Area.sf <- st_buffer(TLH.sf, dist = 100000)

tm_shape(TLH_Area.sf) +
  tm_borders() +
tm_shape(FL_Fires.sf) +
  tm_dots() +
tm_shape(FLcty) +
  tm_borders()
```

Simplify data frame and add empty geometries.
```{r}
library(lubridate)

FL_Fires2.sf <- FL_Fires.sf %>%
  st_intersection(TLH_Area.sf)

  mutate(YMD = ymd(as.Date(DISCOVERY_))) %>%
  group_by(YMD) %>%
  summarize(nF = n())

DateSequence.df <- data.frame(YMD = seq(as.Date("1992-01-01"), as.Date("2015-12-31"), 
                                        by = "days"))
XY <- left_join(alldays.df, FL_Fires2.sf, by = "YMD") %>%
  st_as_sf()

r <- st_is_empty(XY)
```


## A simple equation for rainfall statistics 

https://iopscience.iop.org/article/10.1088/1748-9326/ab2bb2

$$
\Pr(X > x) = f_w \exp(-x/\mu)
$$
where $X$ is the 24 h rainfall and $x$ is the threshold defining heavy precipitation, $f_w$ is the wet-day frequency and $\mu$ is the wet-day mean.

Start with April rainfall only.
```{r}
April.df <- TLH.df %>%
  filter(Month == 4)
```

```{r}
df <- TLH.df %>%
#  filter(Month %in% c(9, 10, 11)) %>%
  group_by(Year) %>%
  summarize(nD = n(),
            fw = sum(Rainfall24mm >= 1)/nD,
            mu = mean(Rainfall24mm[Rainfall24mm > 1]),
            q75 = quantile(Rainfall24mm[Rainfall24mm > 1], probs = .75),
            q95 = quantile(Rainfall24mm[Rainfall24mm > 1], probs = .95),
            q99 = quantile(Rainfall24mm[Rainfall24mm > 1], probs = .99),
            Pr = fw * exp(-50/mu),
            xbar = mu * fw,
            xbar2 = mean(Rainfall24mm[Rainfall24mm >= 0]),
            fraction = sum(Rainfall24mm > 50)/nD,
            avgTmax = mean(MaxTemp[Rainfall24mm > 1]),
            avgTmin = mean(MinTemp[Rainfall24mm > 1])) %>%
  group_by(Month) %>%
  summarize(cc = cor.test(fw, q95)$estimate)

  ggplot(data = df, aes(x = Year, y = avgTmax)) +
    geom_point() +
    geom_smooth(method = lm) +
  facet_wrap(~ Month)
  
ggplot(df, aes(x = q75, y = fw, color = Year)) + 
  geom_point() +
  scale_color_viridis_c()
```

Use percentiles instead of mu? See FreqInt.Rmd on Desktop. Use avgTmax and correlate with EOFs of freq vs intensity.

```{r}
theta = seq(1, 180, by = 1)
r = NULL ; pval = NULL
for (k in theta){
  C1 = cos(k * pi/180)
  C2 = sin(k * pi/180)
  Rclim = C1 * scale(df$q99) + C2 * scale(df$fw)
  ctest = cor.test(Rclim, df$avgTmax)
  r = c(r, as.numeric(ctest$estimate))
  pval = c(pval, as.numeric(ctest$p.value))
}
range(r)

signif = .05
plot(-10, -10, xlim=c(-1, 1.3), ylim=c(-1, 1.3), axes=FALSE, xlab='', ylab='', main='')

i = seq(0, 360, .5)
Outl = cbind(cos(i * pi/180), sin(i * pi/180))
Innl = cbind(.5 * cos(i * pi/180), .5 * sin(i * pi/180))

polygon(Outl[, 1], Outl[, 2], border=colors()[229], col='white', lwd=2)
polygon(Innl[, 1], Innl[, 2], border=colors()[229], col=NULL, lwd=2)

Line.xcord = c(-1, 1, NA, 0, 0, NA, -cos(pi/4), cos(pi/4), NA, -cos(pi/4), cos(pi/4))
Line.ycord = c(0, 0, NA, -1, 1, NA, sin(pi/4), -sin(pi/4), NA, -sin(pi/4), sin(pi/4))
lines(Line.xcord, Line.ycord, col=colors()[229], lwd=1)

text(par('usr')[2] - 0.29, 0.0, srt=0, adj = 0, labels = 'INT', xpd = TRUE, cex=1.3) 
text(par('usr')[2] - 0.6, 0.81, srt=0, adj = 0, labels = 'ACT', xpd = TRUE, cex=1.3)
text(par('usr')[2] - 1.52, 1.17, srt=0, adj = 0, labels = 'FRQ', xpd = TRUE, cex=1.3)
text(par('usr')[2] - 0.6, -0.81, srt=0, adj = 0, labels = 'EINT', xpd = TRUE, cex=1.3)
text(0,0.55, '0.5', cex=1.4, col=colors()[229])
text(0,1.05, '1.0', cex=1.4, col=colors()[229])

dg = theta
polygon(r * cos(dg * pi/180), r * sin(dg * pi/180), border="#ff9900", lwd=7, col=NULL)
r2 = c(r[which.max(pval):length(pval)], r[1:(which.max(pval) - 1)])
pval2 = c(pval[which.max(pval):length(pval)], pval[1:(which.max(pval) - 1)])
dg2 = c(dg[which.max(pval):length(pval)], dg[1:(which.max(pval) - 1)])
lines(r2[pval2 <= signif] * cos(dg2[pval2 <= signif] * pi/180),
      r2[pval2 <= signif] * sin(dg2[pval2 <= signif] * pi/180), col="#cc3300", lwd=7) 
```

Not very enlightening as avgTmax responds to precipitation rather than is a response to precipitation.

Also for plotting see https://dominicroye.github.io/en/2020/visualize-climate-anomalies/

Winter rainfall getting more intense.

